"Saidani I,Ouni A,Mkaouer MW,Palomba F",On the impact of Continuous Integration on refactoring practice: An exploratory study on TravisTorrent,2021,https://www.sciencedirect.com/science/article/pii/S0950584921000914;http://dx.doi.org/10.1016/j.infsof.2021.106618,"Context: The ultimate goal of Continuous Integration (CI) is to support developers in integrating changes into production constantly and quickly through automated build process. While CI provides developers with prompt feedback on several quality dimensions after each change, such frequent and quick changes may in turn compromise software quality without Refactoring. Indeed, recent work emphasized the potential of CI in changing the way developers perceive and apply refactoring. However, we still lack empirical evidence to confirm or refute this assumption. Objective: We aim to explore and understand the evolution of refactoring practices, in terms of frequency, size and involved developers, after the switch to CI in order to emphasize the role of this process in changing the way Refactoring is applied. Method: We collect a corpus of 99,545 commits and 89,926 refactoring operations extracted from 39 open-source GitHub projects that adopt Travis CI and analyze the changes using Multiple Regression Analysis (MRA). Results: Our study delivers several important findings. We found that the adoption of CI is associated with a drop in the refactoring size as recommended, while refactoring frequency as well as the number (and its related rate) of developers that perform refactoring are estimated to decrease after the shift to CI, indicating that refactoring is less likely to be applied in CI context. Conclusion: Our study uncovers insights about CI theory and practice and adds evidence to existing knowledge about CI practices related especially to quality assurance. Software developers need more customized refactoring tool support in the context of CI to better maintain and evolve their software systems."
"Walter B,Fontana FA,Ferme V",Code smells and their collocations: A large-scale experiment on open-source systems,2018,https://www.sciencedirect.com/science/article/pii/S0164121218301109;http://dx.doi.org/10.1016/j.jss.2018.05.057,"Code smells indicate possible flaws in software design, that could negatively affect systemâ€™s maintainability. Interactions among smells located in the same classes (i.e., collocated smells) have even more detrimental effect on quality. Extracted frequent patterns of collocated smells could help to understand practical consequences of collocations. In this paper we identify and empirically validate frequent collocations of 14 code smells detected in 92 Java systems, using three approaches: pairwise correlation analysis, PCA and associative rules. To cross-validate the results, we used up to 6 detectors for each smell. Additionally, we examine and compare techniques used to extract the relationships. The contribution is three-fold: (1) we identify and empirically validate relationships among the examined code smells on a large dataset that we made publicly available, (2) we discuss how the choice of code smell detectors affects results, and (3) we analyze the impact of software domain on existence of the smell collocations. Additionally, we found that analytical methods we used to discover collocations, are complementary. Smells collocations display recurring patterns that could help prioritizing the classes affected by code smells to be refactored and developing or enhancing detectors exploiting information about collocations. They can also help the developers focusing on classes deserving more maintenance effort."
"Saheb-Nassagh R,Ashtiani M,Minaei-Bidgoli B",A probabilistic-based approach for automatic identification and refactoring of software code smells,2022,https://www.sciencedirect.com/science/article/pii/S1568494622007074;http://dx.doi.org/10.1016/j.asoc.2022.109658,"Programmers strive to design programs that are flexible, updateable, and maintainable. However, several factors such as lack of time, high costs, and workload lead to the creation of software with inadequacies known as anti-patterns. To identify and refactor software anti-patterns, many research studies have been conducted using machine learning. Even though some of the previous works were very accurate in identifying anti-patterns, a method that takes into account the relationships between different structures is still needed. Furthermore, a practical method is needed that is trained according to the characteristics of each program. This method should be able to identify anti-patterns and perform the necessary refactorings. This paper proposes a framework based on probabilistic graphical models for identifying and refactoring anti-patterns. A graphical model is created by extracting the class properties from the source code. As a final step, a Bayesian network is trained, which determines whether anti-patterns are present or not based on the characteristics of neighboring classes. To evaluate the proposed approach, the model is trained on six different anti-patterns and six different Java programs. The proposed model has identified these anti-patterns with a mean accuracy of 85.16 percent and a mean recall of 79%. Additionally, this model has been used to introduce several methods for refactoring, and it has been shown that these refactoring methods will ultimately create a system with less coupling and higher cohesion."
"Shahidi M,Ashtiani M,Zakeri-Nasrabadi M",An automated extract method refactoring approach to correct the long method code smell,2022,https://www.sciencedirect.com/science/article/pii/S0164121222000048;http://dx.doi.org/10.1016/j.jss.2022.111221,"Long Method is amongst the most common code smells in software systems. Despite various attempts to detect the long method code smell, few automated approaches are presented to refactor this smell. Extract Method refactoring is mainly applied to eliminate the Long Method smell. However, current approaches still face serious problems such as insufficient accuracy in detecting refactoring opportunities, limitations on correction types, the need for human intervention in the refactoring process, and lack of attention to object-oriented principles, mainly single responsibility and cohesionâ€“coupling principles. This paper aims to automatically identify and refactor the long method smells in Java codes using advanced graph analysis techniques, addressing the aforementioned difficulties. First, a graph representing project entities is created. Then, long method smells are detected, considering the methodsâ€™ dependencies and sizes. All possible refactorings are then extracted and ranked by a modularity metric, emphasizing high cohesion and low coupling classes for the detected methods. Finally, a proper name is assigned to the extracted method based on its responsibility. Subsequently, the best destination class is determined such that design modularity is maximized. Expertsâ€™ opinion is used to evaluate the proposed approach on five different Java projects. The results show the applicability of the proposed method in establishing the single responsibility principle with a 21% improvement compared to the state-of-the-art extract method refactoring approaches."
"Fokaefs M,Tsantalis N,Stroulia E,Chatzigeorgiou A",Identification and application of Extract Class refactorings in object-oriented systems,2012,https://www.sciencedirect.com/science/article/pii/S0164121212001057;http://dx.doi.org/10.1016/j.jss.2012.04.013,"Refactoring is recognized as an essential practice in the context of evolutionary and agile software development. Recognizing the importance of the practice, modern IDEs provide some support for low-level refactorings. A notable exception in the list of supported refactorings is the â€œExtract Classâ€ refactoring, which is conceived to simplify large, complex, unwieldy and less cohesive classes. In this work, we describe a method and a tool, implemented as an Eclipse plugin, designed to fulfill exactly this need. Our method involves three steps: (a) recognition of Extract Class opportunities, (b) ranking of the identified opportunities in terms of the improvement each one is anticipated to bring about to the system design, and (c) fully automated application of the refactoring chosen by the developer. The first step relies on an agglomerative clustering algorithm, which identifies cohesive sets of class members within the system classes. The second step relies on the Entity Placement metric as a measure of design quality. Through a set of experiments we have shown that the tool is able to identify and extract new classes that developers recognize as â€œcoherent conceptsâ€ and improve the design quality of the underlying system."
"Caldeira J,Brito e Abreu F,Cardoso J,dos Reis JP",Unveiling process insights from refactoring practices,2022,https://www.sciencedirect.com/science/article/pii/S0920548921000829;http://dx.doi.org/10.1016/j.csi.2021.103587,"Context: Software comprehension and maintenance activities, such as refactoring, are said to be negatively impacted by software complexity. The methods used to measure software product and processes complexity have been thoroughly debated in the literature. However, the discernment about the possible links between these two dimensions, particularly on the benefits of using the process perspective, has a long journey ahead. Objective: To improve the understanding of the liaison of developersâ€™ activities and software complexity within a refactoring task, namely by evaluating if process metrics gathered from the IDE, using process mining methods and tools, are suitable to accurately classify different refactoring practices and the resulting software complexity. Method: We mined source code metrics from a software product after a quality improvement task was given in parallel to (117) software developers, organized in (71) teams. Simultaneously, we collected events from their IDE work sessions (320) and used process mining to model their processes and extract the correspondent metrics. Results: Most teams using a plugin for refactoring (JDeodorant) reduced software complexity more effectively and with simpler processes than the ones that performed refactoring using only Eclipse native features. We were able to find moderate correlations (â‰ˆ43%) between software cyclomatic complexity and process cyclomatic complexity. Using only process driven metrics, we computed â‰ˆ30,000 models aiming to predict the type of refactoring method (automatic or manual) teams had used and the expected level of software cyclomatic complexity reduction after their work sessions. The best models found for the refactoring method and cyclomatic complexity level predictions, had an accuracy of 92.95% and 94.36%, respectively. Conclusions: We have demonstrated the feasibility of an approach that allows building cross-cutting analytical models in software projects, such as the one we used for detecting manual or automatic refactoring practices. Events from the development tools and support activities can be collected, transformed, aggregated, and analyzed with fewer privacy concerns or technical constraints than source code-driven metrics. This makes our approach agnostic to programming languages, geographic location, or development practices, making it suitable for challenging contexts, such as, in modern global software development where many projects adopt agile methodologies, and low/no code platforms. Initial findings are encouraging, and lead us to suggest practitioners may use our method in other development tasks, such as, defect analysis and unit or integration tests."
Al Dallal J,Identifying refactoring opportunities in object-oriented code: A systematic literature review,2015,https://www.sciencedirect.com/science/article/pii/S0950584914001918;http://dx.doi.org/10.1016/j.infsof.2014.08.002,"Context Identifying refactoring opportunities in object-oriented code is an important stage that precedes the actual refactoring process. Several techniques have been proposed in the literature to identify opportunities for various refactoring activities. Objective This paper provides a systematic literature review of existing studies identifying opportunities for code refactoring activities. Method We performed an automatic search of the relevant digital libraries for potentially relevant studies published through the end of 2013, performed pilot and author-based searches, and selected 47 primary studies (PSs) based on inclusion and exclusion criteria. The PSs were analyzed based on a number of criteria, including the refactoring activities, the approaches to refactoring opportunity identification, the empirical evaluation approaches, and the data sets used. Results The results indicate that research in the area of identifying refactoring opportunities is highly active. Most of the studies have been performed by academic researchers using nonindustrial data sets. Extract Class and Move Method were found to be the most frequently considered refactoring activities. The results show that researchers use six primary existing approaches to identify refactoring opportunities and six approaches to empirically evaluate the identification techniques. Most of the systems used in the evaluation process were open-source, which helps to make the studies repeatable. However, a relatively high percentage of the data sets used in the empirical evaluations were small, which limits the generality of the results. Conclusions It would be beneficial to perform further studies that consider more refactoring activities, involve researchers from industry, and use large-scale and industrial-based systems."
"Cabral JB,SÃ¡nchez B,Ramos F,Gurovich S,Granitto PM,Vanderplas J",From FATS to feets: Further improvements to an astronomical feature extraction tool based on machine learning,2018,https://www.sciencedirect.com/science/article/pii/S2213133718300581;http://dx.doi.org/10.1016/j.ascom.2018.09.005,"Machine learning algorithms are highly useful for the classification of time series data in astronomy in this era of peta-scale public survey data releases. These methods can facilitate the discovery of new unknown events in most astrophysical areas, as well as improving the analysis of samples of known phenomena. Machine learning algorithms use features extracted from collected data as input predictive variables. A public tool called Feature Analysis for Time Series (FATS) has proved an excellent workhorse for feature extraction, particularly light curve classification for variable objects. In this study, we present a major improvement to FATS, which corrects inconvenient design choices, minor details, and documentation for the re-engineering process. This improvement comprises a new Python package called feets, which is important for future code-refactoring for astronomical software tools."
"Tsantalis N,Chatzigeorgiou A",Identification of refactoring opportunities introducing polymorphism,2010,https://www.sciencedirect.com/science/article/pii/S0164121209002337;http://dx.doi.org/10.1016/j.jss.2009.09.017,"Polymorphism is one of the most important features offered by object-oriented programming languages, since it allows to extend/modify the behavior of a class without altering its source code, in accordance to the Open/Closed Principle. However, there is a lack of methods and tools for the identification of places in the code of an existing system that could benefit from the employment of polymorphism. In this paper we propose a technique that extracts refactoring suggestions introducing polymorphism. The approach ensures the behavior preservation of the code and the applicability of the refactoring suggestions based on the examination of a set of preconditions."
"Lenarduzzi V,Lomio F,SaarimÃ¤ki N,Taibi D",Does migrating a monolithic system to microservices decrease the technical debt?,2020,https://www.sciencedirect.com/science/article/pii/S0164121220301539;http://dx.doi.org/10.1016/j.jss.2020.110710,"Background: The migration from a monolithic system to microservices requires a deep refactoring of the system. Therefore, such a migration usually has a big economic impact and companies tend to postpone several activities during this process, mainly to speed up the migration itself, but also because of the demand for releasing new features. Objective: We monitored the technical debt of an SME while it migrated from a legacy monolithic system to an ecosystem of microservices. Our goal was to analyze changes in the code technical debt before and after the migration to microservices. Method: We conducted a case study analyzing more than four years of the history of a twelve-year-old project (280K Lines of Code) where two teams extracted five business processes from the monolithic system as microservices. For the study, we first analyzed the technical debt with SonarQube and then performed a qualitative study with company members to understand the perceived quality of the system and the motivation for possibly postponed activities. Results: The migration to microservices helped to reduce the technical debt in the long run. Despite an initial spike in the technical debt due to the development of the new microservice, after a relatively short period of time the technical debt tended to grow slower than in the monolithic system."
"Kebir S,Borne I,Meslati D",A genetic algorithm-based approach for automated refactoring of component-based software,2017,https://www.sciencedirect.com/science/article/pii/S0950584917302495;http://dx.doi.org/10.1016/j.infsof.2017.03.009,"Context: During its lifecycle, a software system undergoes repeated modifications to quickly fulfill new requirements, but its underlying design is not properly adjusted after each update. This leads to the emergence of bad smells. Refactoring provides a de facto behavior-preserving approach to eliminate these anomalies. However, manually determining and performing useful refactorings is a formidable challenge, as stated in the literature. Therefore, framing object-oriented automated refactoring as a search-based technique has been proposed. However, the literature shows that search-based refactoring of component-based software has not yet received proper attention. Objective: This paper presents a genetic algorithm-based approach for the automated refactoring of component-based software. This approach consists of detecting component-relevant bad smells and eliminating these bad smells by searching for the best sequence of refactorings using a genetic algorithm. Method: Our approach consists of four steps. The first step includes studying the literature related to component-relevant bad smells and formulating bad smell detection rules. The second step involves proposing a catalog of component-relevant refactorings. The third step consists of constructing a source code model by extracting facts from the source code of a component-based software. The final step seeks to identify the best sequence of refactorings to apply to reduce the presence of bad smells in the source code model using a genetic algorithm. The latter uses bad smell detection rules as a fitness function and the catalog of refactorings as a means to explore the search space. Results: As a case study, we conducted experiments on an unbiased set of four real-world component-based applications. The results indicate that our approach is able to efficiently reduce the total number of bad smells by more than one half, which is an acceptable value compared to the recent literature. Moreover, we determined that our approach is also accurate in refactoring only components suffering from bad smells while leaving the remaining components untouched whenever possible. Furthermore, a statistical analysis shows that our genetic algorithm outperforms random search and local search in terms of efficiency and accuracy on almost all the systems investigated in this work. Conclusion: This paper presents a search-based approach for the automated refactoring of component-based software. To the best of our knowledge, our approach is the first to focus on component-based refactoring, whereas the state-of-the-art approaches focus only on object-oriented refactoring."
"Han AR,Bae DH",Dynamic profiling-based approach to identifying cost-effective refactorings,2013,https://www.sciencedirect.com/science/article/pii/S0950584912002376;http://dx.doi.org/10.1016/j.infsof.2012.12.002,"Context Object-oriented software undergoes continuous changesâ€”changes often made without consideration of the softwareâ€™s overall structure and design rationale. Hence, over time, the design quality of the software degrades causing software aging or software decay. Refactoring offers a means of restructuring software design to improve maintainability. In practice, efforts to invest in refactoring are restricted; therefore, the problem calls for a method for identifying cost-effective refactorings that efficiently improve maintainability. Cost-effectiveness of applied refactorings can be explained as maintainability improvement over invested refactoring effort (cost). For the system, the more cost-effective refactorings are applied, the greater maintainability would be improved. There have been several studies of supporting the arguments that changes are more prone to occur in the pieces of codes more frequently utilized by users; hence, applying refactorings in these parts would fast improve maintainability of software. For this reason, dynamic information is needed for identifying the entities involved in given scenarios/functions of a system, and within these entities, refactoring candidates need to be extracted. Objective This paper provides an automated approach to identifying cost-effective refactorings using dynamic information in object-oriented software. Method To perform cost-effective refactoring, refactoring candidates are extracted in a way that reduces dependencies; these are referred to as the dynamic information. The dynamic profiling technique is used to obtain the dependencies of entities based on dynamic method calls. Based on those dynamic dependencies, refactoring-candidate extraction rules are defined, and a maintainability evaluation function is established. Then, refactoring candidates are extracted and assessed using the defined rules and the evaluation function, respectively. The best refactoring (i.e., that which most improves maintainability) is selected from among refactoring candidates, then refactoring candidate extraction and assessment are re-performed to select the next refactoring, and the refactoring identification process is iterated until no more refactoring candidates for improving maintainability are found. Results We evaluate our proposed approach in three open-source projects. The first results show that dynamic information is helpful in identifying cost-effective refactorings that fast improve maintainability; and, considering dynamic information in addition to static information provides even more opportunities to identify cost-effective refactorings. The second results show that dynamic information is helpful in extracting refactoring candidates in the classes where real changes had occurred; in addition, the results also offer the promising support for the contention that using dynamic information helps to extracting refactoring candidates from highly-ranked frequently changed classes. Conclusion Our proposed approach helps to identify cost-effective refactorings and supports an automated refactoring identification process."
Unterholzner M,Improving refactoring tools in Smalltalk using static type inference,2014,https://www.sciencedirect.com/science/article/pii/S0167642313003250;http://dx.doi.org/10.1016/j.scico.2013.11.032,"Refactoring is a crucial activity in agile software development. As a consequence, automated tools are expected to support refactoring, both for reducing the developer's effort as well as for avoiding errors due to manual changes. In this context, the chosen programming language has a major impact on the level of support that an automated refactoring tool can offer. One important aspect of a programming language concerning the automation of refactoring is the type system. While a static type system, present in languages such as Java, provides information about dependencies in the program, the dynamic type system of the Smalltalk programming language offers little information that can be used by automated refactoring tools. This paper focuses on the challenges in the context of refactoring raised by the dynamic type system of Smalltalk. It highlights the problems caused by the absence of static type information and proposes the use of static code analysis for performing type inference to gather information about the dependencies in the program's source code. It explains the mechanism of the static code analysis using sample code and presents a prototype of an enhanced refactoring tool, which uses the structural information extracted through static code analysis. Empirical samples build the base for evaluating the effectiveness of the approach."
"Sandoval Alcocer JP,Siles Antezana A,Santos G,Bergel A",Improving the success rate of applying the extract method refactoring,2020,https://www.sciencedirect.com/science/article/pii/S016764232030085X;http://dx.doi.org/10.1016/j.scico.2020.102475,"Context: Most modern programming environments support refactorings. Although refactorings are relevant to improve the quality of software source code, they unfortunately suffer from severe usability issues. In particular, the extract method refactoring, one of the most prominent refactorings, has a failure rate of 49% when users attempt to use it. Objective: Our main objective is to improve the success rate of applying the extract method refactoring. Methods: First, to understand the cause of refactoring failure, we conducted a partial replication of Vakilian's ICSE '14 study about usability issues of refactoring using IntelliJ IDEA. Second, we designed and implemented TOAD, a tool that proposes alternative text selection for source code refactoring for the Pharo programming language. Third, we evaluated TOAD using a controlled experiment against the standard Pharo code refactoring tool. Seven professional software engineers complemented with three undergrad students participated in our experiments. Conclusion: The causes we identified of failed extract method refactoring attempts match Vakilian's work. TOAD significantly reduces the number of failed attempts to run the extract method refactoring at a lower cognitive load cost."
"AlOmar EA,Ivanov A,Kurbatova Z,Golubev Y,Mkaouer MW,Ouni A,Bryksin T,Nguyen L,Kini A,Thakur A",Just-in-time code duplicates extraction,2023,https://www.sciencedirect.com/science/article/pii/S095058492300023X;http://dx.doi.org/10.1016/j.infsof.2023.107169,"Context: Refactoring is a critical task in software maintenance, and is usually performed to enforce better design and coding practices, while coping with design defects. The Extract Method refactoring is widely used for merging duplicate code fragments into a single new method. Several studies attempted to recommend Extract Method refactoring opportunities using different techniques, including program slicing, program dependency graph analysis, change history analysis, structural similarity, and feature extraction. However, irrespective of the method, most of the existing approaches interfere with the developerâ€™s workflow: they require the developer to stop coding and analyze the suggested opportunities, and also consider all refactoring suggestions in the entire project without focusing on the development context. Objective: To increase the adoption of the Extract Method refactoring, in this paper, we aim to investigate the effectiveness of machine learning and deep learning algorithms for its recommendation while maintaining the workflow of the developer. Method: The proposed approach relies on mining prior applied Extract Method refactorings and extracting their features to train a deep learning classifier that detects them in the userâ€™s code. We implemented our approach as a plugin for IntelliJ IDEA called AntiCopyPaster. To develop our approach, we trained and evaluated various popular models on a dataset of 18,942 code fragments from 13 Open Source Apache projects. Results: The results show that the best model is the Convolutional Neural Network (CNN), which recommends appropriate Extract Method refactorings with an F-measure of 0.82. We also conducted a qualitative study with 72 developers to evaluate the usefulness of the developed plugin. Conclusion: The results show that developers tend to appreciate the idea of the approach and are satisfied with various aspects of the pluginâ€™s operation."
"Tsantalis N,Chatzigeorgiou A",Identification of extract method refactoring opportunities for the decomposition of methods,2011,https://www.sciencedirect.com/science/article/pii/S0164121211001191;http://dx.doi.org/10.1016/j.jss.2011.05.016,"The extraction of a code fragment into a separate method is one of the most widely performed refactoring activities, since it allows the decomposition of large and complex methods and can be used in combination with other code transformations for fixing a variety of design problems. Despite the significance of Extract Method refactoring towards code quality improvement, there is limited support for the identification of code fragments with distinct functionality that could be extracted into new methods. The goal of our approach is to automatically identify Extract Method refactoring opportunities which are related with the complete computation of a given variable (complete computation slice) and the statements affecting the state of a given object (object state slice). Moreover, a set of rules regarding the preservation of existing dependences is proposed that exclude refactoring opportunities corresponding to slices whose extraction could possibly cause a change in program behavior. The proposed approach has been evaluated regarding its ability to capture slices of code implementing a distinct functionality, its ability to resolve existing design flaws, its impact on the cohesion of the decomposed and extracted methods, and its ability to preserve program behavior. Moreover, precision and recall have been computed employing the refactoring opportunities found by independent evaluators in software that they developed as a golden set."
"Smiari P,Bibi S,Ampatzoglou A,Arvanitou EM",Refactoring embedded software: A study in healthcare domain,2022,https://www.sciencedirect.com/science/article/pii/S0950584921002068;http://dx.doi.org/10.1016/j.infsof.2021.106760,"Context In embedded software industry, stakeholders usually promote run-time properties (e.g., performance, energy efficiency, etc.) as quality drivers, which in many cases leads to a compromise at the levels of design-time qualities (e.g., maintainability, reusability, etc.). Such a compromise does not come without a cost; since embedded systems need heavy maintenance cycles. To assure effective bug-fixing, shorten the time required for releasing updates, a refactoring of the software codebase needs to take place regularly. Objective: This study aims to investigate how refactorings are applied in ES industry; and propose a systematic approach that can guide refactoring through a 3-step process for refactoring: (a) planning; (b) design; and (c) evaluation. Method The aforementioned goals were achieved by conducting a single case study in a company that develops medical applications for bio-impedance devices; and follows a rather systematic refactoring process in periodic timestamps. Three data collection approaches have been used: surveys, interviews (10 practitioners), and artifact analysis (51 refactoring activities). Results The results of the study suggest that: (a) maintainability and reusability are the design-time quality attributes that motivate the refactoring of Embedded Software (ES), with 30% of the participants considering them as of â€œVery Highâ€ importance; (b) the refactorings that are most frequently performed are â€œExtract Methodâ€, â€œReplace Magic Number with Constantâ€ and â€œRemove Parameterâ€. We note that the â€œExtract Methodâ€ refactoring has an applicability of more than over 80%; and (c) to evaluate the refactoring process engineers use tools producing structural metrics, internal standards, and reviews. Conclusions The outcomes of this study can be useful to both researchers and practitioners, in the sense that the former can focus their efforts on aspects that are meaningful to industry, whereas the latter are provided with a systematic refactoring process."
"HegedÅ±s P,KÃ¡dÃ¡r I,Ferenc R,GyimÃ³thy T",Empirical evaluation of software maintainability based on a manually validated refactoring dataset,2018,https://www.sciencedirect.com/science/article/pii/S0950584916303561;http://dx.doi.org/10.1016/j.infsof.2017.11.012,"Context Refactoring is a technique for improving the internal structure of software systems. It has a solid theoretical background while being used in development practice also. However, we lack empirical research results on the real effect of code refactoring and its application. Objective This paper presents a manually validated subset of a previously published dataset containing the refactorings extracted by the RefFinder tool, code metrics, and maintainability of 7 open-source systems. We found that RefFinder had around 27% overall average precision on the subject systems, thus our manually validated subset has substantial added value. Using the dataset, we studied several aspects of the refactored and non-refactored source code elements (classes and methods), like the differences in their maintainability and source code metrics. Method We divided the source code elements into a group containing the refactored elements and a group with non-refactored elements. We analyzed the elementsâ€™ characteristics in these groups using correlation analysis, Mannâ€“Whitney U test and effect size measures. Results Source code elements subjected to refactorings had significantly lower maintainability than elements not affected by refactorings. Moreover, refactored elements had significantly higher size related metrics, complexity, and coupling. Also these metrics changed more significantly in the refactored elements. The results are mostly in line with our previous findings on the not validated dataset, with the difference that clone metrics had no strong connection with refactoring. Conclusions Compared to the preliminary analysis using a not validated dataset, the manually validated dataset led to more significant results, which suggests that developers find targets for refactorings based on some internal quality properties of the source code, like their size, complexity or coupling, but not clone related metrics as reported in our previous studies. They do not just use these properties for identifying targets, but also control them with refactorings."
"Bian Y,Koru G,Su X,Ma P",SPAPE: A semantic-preserving amorphous procedure extraction method for near-miss clones,2013,https://www.sciencedirect.com/science/article/pii/S0164121213000733;http://dx.doi.org/10.1016/j.jss.2013.03.061,"Cloned code, also known as duplicated code, is among the bad â€œcode smellsâ€. Procedure extraction can be used to remove clones and to make a software system more maintainable. While the existing procedure extraction techniques can handle automatic extraction of exact clones effectively, they fail to do so for near-miss clones, which are the code fragments that are similar but not the same. To address this gap, we developed SPAPE, a novel semantic-preserving amorphous procedure extraction method to extract near-miss clones. SPAPE relaxes the constraint of having the same syntax and uses the structural semantic information. We evaluated the performance, effectiveness, and benefits of SPAPE. Our results show that SPAPE can extract more near-miss clones than the best applicable method for ten open-source-software products in an efficient and effective fashion. We conclude that SPAPE can be a useful contribution to the toolsets of software managers and developers, and it can help them improve code structure and reduce software maintenance and overall project costs."
"Wang S,Bansal C,Nagappan N",Large-scale intent analysis for identifying large-review-effort code changes,2021,https://www.sciencedirect.com/science/article/pii/S0950584920300033;http://dx.doi.org/10.1016/j.infsof.2020.106408,"Context: Code changes to software occur due to various reasons such as bug fixing, new feature addition, and code refactoring. Change intents have been studied for years to help developers understand the rationale behind code commits. However, in most existing studies, the intent of the change is rarely leveraged to provide more specific, context aware analysis. Objective: In this paper, we present the first study to leverage change intent to characterize and identify Large-Review-Effort (LRE) changesâ€”changes with large review effort. Method: Specifically, we first propose a feedback-driven and heuristics-based approach to identify change intents of code changes. We then characterize the changes regarding review effort by using various features extracted from change metadata and the change intents. We further explore the feasibility of automatically classifying LRE changes. We conduct our study on four large-scale projects, one from Microsoft and three are open source projects, i.e., Qt, Android, and OpenStack. Results: Our results show that, (i) code changes with some intents (i.e., Feature and Refactor) are more likely to be LRE changes, (ii) machine learning based prediction models are applicable for identifying LRE changes, and (iii) prediction models built for code changes with some intents achieve better performance than prediction models without considering the change intent, the improvement in AUC can be up to 19 percentage points and is 7.4 percentage points on average. Conclusion: The change intent analysis and its application on LRE identification proposed in this study has already been used in Microsoft to provide the review effort and intent information of changes for reviewers to accelerate the review process. To show how to deploy our approaches in real-world practice, we report a case study of developing and deploying the intent analysis system in Microsoft. Moreover, we also evaluate the usefulness of our approaches by using a questionnaire survey. The feedback from developers demonstrate its practical value."
"Zhang Y,Ge C,Hong S,Tian R,Dong C,Liu J",DeleSmell: Code smell detection based on deep learning and latent semantic analysis,2022,https://www.sciencedirect.com/science/article/pii/S0950705122008796;http://dx.doi.org/10.1016/j.knosys.2022.109737,"The presence of code smells will increase the risk of failure, make software difficult to maintain, and introduce potential technique debt in the future. Although many deep-learning-based approaches have been proposed to detect code smells, most existing works suffer from the problem of incomplete feature extraction and unbalanced distribution between positive samples and negative samples. Furthermore, the accuracy of existing works can be further improved. This paper proposes a novel approach named DeleSmell to detect code smells based on a deep learning model. The dataset is built by extracting samples from 24 real-world projects. To improve the imbalance in the dataset, a refactoring tool is developed to automatically transform good source code into smelly code and to generate positive samples based on real cases. DeleSmell collects both structural features through iPlasma and semantic features via latent semantic analysis and word2vec. DeleSmellâ€™s model includes a convolutional neural network(CNN) branch and gate recurrent unit(GRU)-attention branch. The final classification is conducted by an support vector machine(SVM). In the experimentation, the effectiveness of DeleSmell is evaluated by answering seven research questions. The experimental results show that DeleSmell improves the accuracy of brain class (BC) and brain method (BM) code smells detection by up to 4.41% compared with existing approaches, demonstrating the effectiveness of our approach."
"Bavota G,De Lucia A,Oliveto R",Identifying Extract Class refactoring opportunities using structural and semantic cohesion measures,2011,https://www.sciencedirect.com/science/article/pii/S0164121210003195;http://dx.doi.org/10.1016/j.jss.2010.11.918,"Abstract Approaches for improving class cohesion identify refactoring opportunities using metrics that capture structural relationships between the methods of a class, e.g., attribute references. Semantic metrics, e.g., C3 metric, have also been proposed to measure class cohesion, as they seem to complement structural metrics. However, until now semantic relationships between methods have not been used to identify refactoring opportunities. In this paper we propose an Extract Class refactoring method based on graph theory that exploits structural and semantic relationships between methods. The empirical evaluation of the proposed approach highlighted the benefits provided by the combination of semantic and structural measures and the potential usefulness of the proposed method as a feature for software development environments."
"Pourasghar B,Izadkhah H,Isazadeh A,Lotfi S",A graph-based clustering algorithm for software systems modularization,2021,https://www.sciencedirect.com/science/article/pii/S0950584920302147;http://dx.doi.org/10.1016/j.infsof.2020.106469,"Context: Clustering algorithms, as a modularization technique, are used to modularize a program aiming to understand large software systems as well as software refactoring. These algorithms partition the source code of the software system into smaller and easy-to-manage modules (clusters). The resulting decomposition is called the software system structure (or software architecture). Due to the NP-hardness of the modularization problem, evolutionary clustering approaches such as the genetic algorithm have been used to solve this problem. These methods do not make much use of the information and knowledge available in the artifact dependency graph which is extracted from the source code. Objective: To overcome the limitations of the existing modularization techniques, this paper presents a new modularization technique named GMA (Graph-based Modularization Algorithm). Methods: In this paper, a new graph-based clustering algorithm is presented for software modularization. To this end, the depth of relationships is used to compute the similarity between artifacts, as well as seven new criteria are proposed to evaluate the quality of a modularization. The similarity presented in this paper enables the algorithm to use graph-theoretic information. Results: To demonstrate the applicability of the proposed algorithm, ten folders of Mozilla Firefox with different domains and functions, along with four other applications, are selected. The experimental results demonstrate that the proposed algorithm produces modularization closer to the human expertâ€™s decomposition (i.e., directory structure) than the other existing algorithms. Conclusion: The proposed algorithm is expected to help a software designer in the software reverse engineering process to extract easy-to-manage and understandable modules from source code."