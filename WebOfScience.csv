"Bashir RS,Lee SP,Yung CC,Alam KA,Ahmad RW",A methodology for impact evaluation of refactoring on external quality attributes of a software design,2017,http://dx.doi.org/10.1109/FIT.2017.00040,"Refactoring aims at improving software design quality without affecting external behavior. It is commonly believed that refactoring operations always enhance the software quality. However, some recent empirical studies have reported negative or negligible effects of refactoring on certain quality attributes. The actual impact of each refactroing on certain quality attributes may help developers in selecting the most suitable refactoring alternatives. Various work have been proposed in this regard at source code-level. However, fewer studies have assessed the refactoring impact at design-level. In this study, We propose a refactoring impact evaluation method enabling developers to select the suitable refactoring operations based on their impact. Nine small scale case studies have been used to validate the consistency of propose method. The results reveal that move method, extract method, extract class rafactoring operations have improved maintainability, understandability, modifiability, and analyzability in nine case studies. These obeservations are consistent accross multiple case studies, implying that the proposed approach is highly consistent."
"AlOmar EA,Liu J,Addo K,Mkaouer MW,Newman C,Ouni A,Yu Z",On the documentation of refactoring types,2022,http://dx.doi.org/10.1007/s10515-021-00314-w,"Commit messages are the atomic level of software documentation. They provide a natural language description of the code change and its purpose. Messages are critical for software maintenance and program comprehension. Unlike documenting feature updates and bug fixes, little is known about how developers document their refactoring activities. Specifically, developers can perform multiple refactoring operations, including moving methods, extracting classes, renaming attributes, for various reasons, such as improving software quality, managing technical debt, and removing defects. Yet, there is no systematic study that analyzes the extent to which the documentation of refactoring accurately describes the refactoring operations performed at the source code level. Therefore, this paper challenges the ability of refactoring documentation, written in commit messages, to adequately predict the refactoring types, performed at the commit level. Our analysis relies on the text mining of commit messages to extract the corresponding features (i.e., keywords) that better represent each class (i.e., refactoring type). The extraction of text patterns, specific to each refactoring type (e.g., rename, extract, move, inline, etc.) allows the design of a model that verifies the consistency of these patterns with their corresponding refactoring. Such verification process can be achieved via automatically predicting, for a given commit, the method-level type of refactoring being applied, namely Extract Method, Inline Method, Move Method, Pull-up Method, Push-down Method, and Rename Method. We compared various classifiers, and a baseline keyword-based approach, in terms of their prediction performance, using a dataset of 5004 commits. Our main findings show that the complexity of refactoring type prediction varies from one type to another. Rename Method and Extract Method were found to be the best documented refactoring activities, while Pull-up Method, and Push-down Method were the hardest to be identified via textual descriptions. Such findings bring the attention of developers to the necessity of paying more attention to the documentation of these types."
"Hora A,Robbes R",Characteristics of method extractions in Java: a large scale empirical study,2020,http://dx.doi.org/10.1007/s10664-020-09809-8,"Extract method is the ``Swiss army knife'' of refactorings: developers perform method extraction to introduce alternative signatures, decompose long code, improve testability, among many other reasons. Although the rationales behind method extraction are well explored, we are not yet aware of its characteristics. Assessing this information can provide the basis to better understand this important refactoring operation as well as improve refactoring tools and techniques based on the actual behavior of developers. In this paper, we assess characteristics of the extract method refactoring. We rely on a state-of-the-art technique to detect method extraction, and analyze over 70K instances of this refactoring, mined from 124 software systems. We investigate five aspects of this operation: magnitude, content, transformation, size, and degree. We find that (i) the extract method is among the most popular refactorings; (ii) extracted methods are over represented on operations related to creation, validation, and setup; (iii) methods that are targets of the extractions are 2.2x longer than the average, and they are reduced by one statement after the extraction; and (iv) single method extraction represents most, but not all, of the cases. We conclude by proposing improvements to refactoring detection, suggestion, and automation tools and techniques to support both practitioners and researchers."
Antezana AS,TOAD: A Tool for Recommending Auto-Refactoring Alternatives,2019,http://dx.doi.org/10.1109/ICSE-Companion.2019.00071,"Developers often face usability problems when trying to adopt refactoring tools. We replicate a user study to identify and categorize these problems, and we propose a tool that guides the developer to select the correct piece of code for Extract Method refactoring. Our tool works during the workflow of refactoring activities and selects candidate selections that (i) are syntactically correct and (ii) meet the necessary preconditions for Extract Method."
"Sandoval Alcocer JP,Antezana AS,Santos G,Bergel A",Improving the success rate of applying the extract method refactoring,2020,http://dx.doi.org/10.1016/j.scico.2020.102475,"Context: Most modern programming environments support refactorings. Although refactorings are relevant to improve the quality of software source code, they unfortunately suffer from severe usability issues. In particular, the extract method refactoring, one of the most prominent refactorings, has a failure rate of 49% when users attempt to use it. Objective: Our main objective is to improve the success rate of applying the extract method refactoring. Methods: First, to understand the cause of refactoring failure, we conducted a partial replication of Vakilian's ICSE `14 study about usability issues of refactoring using IntelliJ IDEA. Second, we designed and implemented TOAD, a tool that proposes alternative text selection for source code refactoring for the Pharo programming language. Third, we evaluated TOAD using a controlled experiment against the standard Pharo code refactoring tool. Seven professional software engineers complemented with three undergrad students participated in our experiments. Conclusion: The causes we identified of failed extract method refactoring attempts match Vakilian's work. TOAD significantly reduces the number of failed attempts to run the extract method refactoring at a lower cognitive load cost. (C) 2020 Elsevier B.V. All rights reserved."
"Liu W,Liu H",Major motivations for extract method refactorings: analysis based on interviews and change histories,2016,http://dx.doi.org/10.1007/s11704-016-5131-4,"Extract method is one of the most popular software refactorings. However, little work has been done to investigate or validate the major motivations for such refactorings. Digging into this issue might help researchers to improve tool support for extract method refactorings, e.g., proposing better tools to recommend refactoring opportunities, and to select fragments to be extracted. To this end, we conducted an interview with 25 developers, and our results suggest that current reuse, decomposition of long methods, clone resolution, and future reuse are the major motivations for extract method refactorings.We also validated the results by analyzing the refactoring history of seven open-source applications. Analysis results suggest that current reuse was the primary motivation for 56% of extract method refactorings, decomposition of methods was the primary motivation for 28% of extract method refactorings, and clone resolution was the primary motivation for 16% of extract method refactorings. These findings might suggest that recommending extract method opportunities by analyzing only the inner structure (e.g., complexity and length) of methods alone would miss many extract method opportunities. These findings also suggest that extract method refactorings are often driven by current and immediate reuse. Consequently, how to recognize or predict reuse requirements timely during software evolution may play a key role in the recommendation and automation of extract method refactorings. We also investigated the likelihood for the extracted methods to be reused in future, and our results suggest that such methods have a small chance Received April 2, 2015; accepted November 10, 2015 E-mail: Liuhui08@bit.edu.cn (12%) to be reused in future unless the extracted fragment could be reused immediately in software evolution and extracting such a fragment can resolve existing clones at the same time."
"Haas R,Hummel B",Deriving Extract Method Refactoring Suggestions for Long Methods,2016,http://dx.doi.org/10.1007/978-3-319-27033-3_10,"The extract method is a common way to shorten long methods in software development. Before developers can use tools that support the extract method, they need to invest time in identifying a suitable refactoring candidate. This paper addresses the problem of finding the most appropriate refactoring candidate for long methods written in Java. The approach determines valid refactoring candidates and ranks them using a scoring function that aims to improve readability and reduce code complexity. We use length and nesting reduction as complexity indicators. The number of parameters needed by the candidate influences the score. To suggest candidates that are consistent with the structure of the code, information such as comments and blank lines are also considered by the scoring function. We evaluate our approach to three open source systems using a user study with ten experienced developers. Our results show that they would actually apply 86% of suggestions for an extract method refactoring."
"Yang L,Liu H,Niu Z",Identifying Fragments to Be Extracted from Long Methods,2009,http://dx.doi.org/10.1109/APSEC.2009.20,"Long and complex methods are hard to read or maintain, and thus usually treated as bad smells, known as Long Method. On the contrary, short and well-named methods are much easier to read, maintain, and extend. In order to divide long methods into short ones, refactoring Extract Method was proposed and has been widely used. However, extracting methods manually is time consuming and error prone. Though existing refactoring tools can automatically extract a selected fragment from its inclosing method, which fragment within a long method should be extracted has to be determined manually. In order to facilitate the decision-making, we propose an approach to recommend fragments within long methods for extraction. The approach is implemented as a prototype, called AutoMeD. With the tool, we evaluate the approach on a non-trivial open source project. The evaluation results suggest that refactoring cost of long methods can be reduced by nearly 40%. The main contribution or this paper is an approach to recommending fragments within long methods to he extracted, as well as an initial evaluation of the approach."
"Haas R,Hummel B",Learning to Rank Extract Method Refactoring Suggestions for Long Methods,2017,http://dx.doi.org/10.1007/978-3-319-49421-0_4,"Extract method refactoring is a common way to shorten long methods in software development. It improves code readability, reduces complexity, and is one of the most frequently used refactorings. Nevertheless, sometimes developers refrain from applying it because identifying an appropriate set of statements that can be extracted into a new method is error-prone and time-consuming. In a previous work, we presented a method that could be used to automatically derive extract method refactoring suggestions for long Java methods, that generated useful suggestions for developers. The approach relies on a scoring function that ranks all valid refactoring possibilities (that is, all candidates) to identify suitable candidates for an extract method refactoring that could be suggested to developers. Even though the evaluation has shown that the suggestions are useful for developers, there is a lack of understanding of the scoring function. In this paper, we present research on the single scoring features, and their importance for the ranking capability. In addition, we evaluate the ranking capability of the suggested scoring function, and derive a better and less complex one using learning to rank techniques."
"Shahidi M,Ashtiani M,Zakeri-Nasrabadi M",An automated extract method refactoring approach to correct the long method code smell,2022,http://dx.doi.org/10.1016/j.jss.2022.111221,"Long Method is amongst the most common code smells in software systems. Despite various attempts to detect the long method code smell, few automated approaches are presented to refactor this smell. Extract Method refactoring is mainly applied to eliminate the Long Method smell. However, current approaches still face serious problems such as insufficient accuracy in detecting refactoring opportunities, limitations on correction types, the need for human intervention in the refactoring process, and lack of attention to object-oriented principles, mainly single responsibility and cohesion-coupling principles. This paper aims to automatically identify and refactor the long method smells in Java codes using advanced graph analysis techniques, addressing the aforementioned difficulties. First, a graph representing project entities is created. Then, long method smells are detected, considering the methods' dependencies and sizes. All possible refactorings are then extracted and ranked by a modularity metric, emphasizing high cohesion and low coupling classes for the detected methods. Finally, a proper name is assigned to the extracted method based on its responsibility. Subsequently, the best destination class is determined such that design modularity is maximized. Experts' opinion is used to evaluate the proposed approach on five different Java projects. The results show the applicability of the proposed method in establishing the single responsibility principle with a 21% improvement compared to the state-of-the-art extract method refactoring approaches. (C)& nbsp;2022 Elsevier Inc. All rights reserved."
"Tsantalis N,Chatzigeorgiou A",Identification of Extract Method Refactoring Opportunities,2009,http://dx.doi.org/10.1109/CSMR.2009.23,"Extract Method has been recognized as one of the most important refactorings, since it decomposes large methods and can be used in combination with other refactorings for fixing a variety of design problems. However, existing tools and methodologies support extraction of methods based on a set of statements selected by the user in the original method The goal of the proposed methodology is to automatically identify Extract Method refactoring opportunities and present them as suggestions to the designer of an object- oriented system. The suggested refactorings adhere to three principles: the extracted code should contain the complete computation of a given variable declared in the original method, the behavior of the program should be preserved after the application of the refactoring, and the extracted code should not be excessively duplicated in the original method The proposed approach is based on the union of static slices that result from the application of a block-based slicing technique. The soundness of the identified refactoring opportunities has been evaluated by an independent designer on the system that he developed"
"Pinto AF,Terra R",Better Similarity Coefficients to Identify Refactoring Opportunities,2017,http://dx.doi.org/10.1145/3132498.3132511,"Similarity coefficients are used by several techniques to identify refactoring opportunities. As an example, it is expected that a method is located in a class that is structurally similar to it. However, the existing coefficients in Literature have not been designed for the structural analysis of software systems, which may not guarantee satisfactory accuracy. This paper, therefore, proposes new coefficients-based on genetic algorithms over a training set of ten systems-to improve the accuracy of the identification of Move Class, Move Method, and Extract Method refactoring opportunities. We conducted an empirical study comparing these proposed coefficients with other 18 coefficients in other 101 systems. The results indicate, in relation to the best analyzed coefficient, an improvement of 10.57% for the identification of Move Method refactoring opportunities, 3.17% for Move Class, and 0.30% for Extract Method. Moreover, we implemented a tool that relies on the proposed coefficients to recommend refactoring opportunities."
"van der Leij D,Binda J,van Dalen R,Vallen P,Luo Y,Aniche M",Data-Driven Extract Method Recommendations: A Study at ING,2021,http://dx.doi.org/10.1145/3468264.3473927,"The sound identification of refactoring opportunities is still an open problem in software engineering. Recent studies have shown the effectiveness of machine learning models in recommending methods that should undergo different refactoring operations. In this work, we experiment with such approaches to identify methods that should undergo an Extract Method refactoring, in the context of ING, a large financial organization. More specifically, we (i) compare the code metrics distributions, which are used as features by the models, between open-source and ING systems, (ii) measure the accuracy of different machine learning models in recommending Extract Method refactorings, (iii) compare the recommendations given by the models with the opinions of ING experts. Our results show that the feature distributions of ING systems and open-source systems are somewhat different, that machine learning models can recommend Extract Method refactorings with high accuracy, and that experts tend to agree with most of the recommendations of the model."
"Tsantalis N,Chatzigeorgiou A",Identification of extract method refactoring opportunities for the decomposition of methods,2011,http://dx.doi.org/10.1016/j.jss.2011.05.016,"The extraction of a code fragment into a separate method is one of the most widely performed refactoring activities, since it allows the decomposition of large and complex methods and can be used in combination with other code transformations for fixing a variety of design problems. Despite the significance of Extract Method refactoring towards code quality improvement, there is limited support for the identification of code fragments with distinct functionality that could be extracted into new methods. The goal of our approach is to automatically identify Extract Method refactoring opportunities which are related with the complete computation of a given variable (complete computation slice) and the statements affecting the state of a given object (object state slice). Moreover, a set of rules regarding the preservation of existing dependences is proposed that exclude refactoring opportunities corresponding to slices whose extraction could possibly cause a change in program behavior. The proposed approach has been evaluated regarding its ability to capture slices of code implementing a distinct functionality, its ability to resolve existing design flaws, its impact on the cohesion of the decomposed and extracted methods, and its ability to preserve program behavior. Moreover, precision and recall have been computed employing the refactoring opportunities found by independent evaluators in software that they developed as a golden set. (C) 2011 Elsevier Inc. All rights reserved."
"Xu S,Sivaraman A,Khoo SC,Xu J",GEMS: An Extract Method Refactoring Recommender,2017,http://dx.doi.org/10.1109/ISSRE.2017.35,"Extract Method is a widely used refactoring operation to improve method comprehension and maintenance. Much research has been done to extract codefragments within the method body to form a new method. Criteria used for identifying extractable code is usually centered around degrees of cohesiveness, coupling and length of the method. However, automatic method extraction techniques have not been highly successful, since it can be hard to concretizethe criteria. In this work, we present a novel system that learns these criteria for Extract Method refactorings from open source repositories. We extractstructural and functional features, which encode the concepts of complexity, cohesion and coupling in our learning model, and train it to extract suitablecode fragments from a given source of a method. Our tool, GEMS, recommends a ranked list of code fragments with high accuracy and greatspeed. We evaluated our approach on several open source repositories and compared it against three state-of-the-art approaches-SEMI, JExtract andJDeodorant. The results on these open-source data show the superiority of our machine-learning-based approach in terms of effectiveness. We develop GEMS asan Eclipse plugin, with the intention to support software reliability through method extraction."
"Maruyama K,Hayashi S",A Tool Supporting Postponable Refactoring,2017,http://dx.doi.org/10.1109/ICSE-C.2017.108,"Failures of precondition checking when attempting to apply automated refactorings often discourage programmers from attempting to use these refactorings in the future. To alleviate this situation, the postponement of the failed refactoring instead its cancellation is beneficial. This poster paper proposes a new concept of postponable refactoring and a prototype tool that implements postponable EXTRACT METHOD as an Eclipse plug-in. We believe that this refactoring tool inspires a new field of reconciliation automated and manual refactoring."
"Schaefer M,Verbaere M,Ekman T,de Moor O",Stepping Stones over the Refactoring Rubicon Lightweight Language Extensions to Easily Realise Refactorings,2009,,"Refactoring tools allow the programmer to pretend they are working with a richer language where the behaviour of a program is automatically preserved during restructuring. In this paper we show that this metaphor of an extended language yields a very general and useful implementation technique for refactorings: a refactoring is implemented by embedding the source program into an extended language on which the refactoring operations are easier to perform, and then translating the refactored program back into the original language. Using the well-known Extract Method refactoring as an example, we show that this approach allows a very fine-grained decomposition of the overall refactoring into a series of micro-refactorings that can be understood, implemented, and tested independently. We thus can easily write implementations of complex refactorings that rival and even outperform industrial strength refactoring tools in terms of correctness, but are much shorter and easier to understand."
"Rongviriyapanish S,Karunlanchakorn N,Meananeatra P",Automatic Code Locations Identification for replacing temporary variable with query method,2015,,"Automatic application of refactoring techniques can help developer save effort for removing bad smells from their code which improves software maintainability. To remove automatically long method bad smell, which is one of the most serious bad smells, we need an automatic application of six refactoring techniques. However, only one refactoring technique ``Extract Method'' can be automated. In this research, we propose an algorithm to identify code locations which will be extracted for creating a query method. We performed an experiment to conclude the workability and correctness of our algorithm. This is the most important step towards an automatic application of refactoring technique ``replace temp with query''."
"Vittek M,Borovansky P,Moreau PE",A C plus plus refactoring browser and method extraction,2006,,"This paper presents a refactoring tool for C++. Its implementation illustrates the main difficulties of automated refactoring raising in this case from the preprocessor and from the complexity of the language. Our solution, using a back-mapping preprocessor, works in the presence of complex preprocessor constructions built upon file inclusions, macro expansions and conditional compilations. Refactorings are computed after full preprocessing and parsing of target programs, hence, they are based on the same level of program understanding as performed by compilers. The paper illustrates the main ideas of our approach on the example of Extract Method refactoring.(3)."
"Smiari P,Bibi S,Ampatzoglou A,Arvanitou EM",Refactoring embedded software: A study in healthcare domain,2022,http://dx.doi.org/10.1016/j.infsof.2021.106760,"Context: In embedded software industry, stakeholders usually promote run-time properties (e.g., performance, energy efficiency, etc.) as quality drivers, which in many cases leads to a compromise at the levels of design-time qualities (e.g., maintainability, reusability, etc.). Such a compromise does not come without a cost; since embedded systems need heavy maintenance cycles. To assure effective bug-fixing, shorten the time required for releasing updates, a refactoring of the software codebase needs to take place regularly. Objective: This study aims to investigate how refactorings are applied in ES industry; and propose a systematic approach that can guide refactoring through a 3-step process for refactoring: (a) planning; (b) design; and (c) evaluation. Method: The aforementioned goals were achieved by conducting a single case study in a company that develops medical applications for bio-impedance devices; and follows a rather systematic refactoring process in periodic timestamps. Three data collection approaches have been used: surveys, interviews (10 practitioners), and artifact analysis (51 refactoring activities). Results: The results of the study suggest that: (a) maintainability and reusability are the design-time quality attributes that motivate the refactoring of Embedded Software (ES), with 30% of the participants considering them as of ``Very High'' importance; (b) the refactorings that are most frequently performed are ``Extract Method'', ``Replace Magic Number with Constant'' and ``Remove Parameter''. We note that the ``Extract Method'' refactoring has an applicability of more than over 80%; and (c) to evaluate the refactoring process engineers use tools producing structural metrics, internal standards, and reviews. Conclusions: The outcomes of this study can be useful to both researchers and practitioners, in the sense that the former can focus their efforts on aspects that are meaningful to industry, whereas the latter are provided with a systematic refactoring process."
"Fornaia A,Tramontana E",Assisting Replace Method with Method Object: selecting fields and preserving data access,2018,http://dx.doi.org/10.1109/COMPSAC.2018.10293,"The work of decomposing long methods into smaller ones is commonly assisted by the Extract Method refactoring technique. However, local variable usages can make code extraction difficult. Therefore, Replace Method with Method Object refactoring technique lets the developer create a field for each variable, and then code extractions can be performed without worrying about variable dependences. However, this can lead to classes having many fields used by a few of its methods. Moreover, the considered fields may not correctly describe the actual object state, making the class harder to understand. This paper proposes a data dependence analysis approach for guiding the Replace Method with Method Object refactoring technique, with the aim of reducing the set of variables becoming fields while properly handling data dependence. The resulting class is easier to understand, having less fields holding the state, while using local variables and parameters to confine all the other data dependence details."
"Marticorena R,Lopez C,Crespo Y,Javier Perez F",Refactoring generics in JAVA: a case study on Extract Method,2010,http://dx.doi.org/10.1109/CSMR.2010.38,"The addition of support for genericity to mainstream programming languages has a notable influence in refactoring tools. This also applies to the JAVA programming language. Those versions of the language specification prior to JAVA 5 did not include support for generics. Therefore, refactoring tools had to evolve to modify their refactoring implementations according to the new language characteristics in order to assure the correct effects when transforming code containing generic definitions or using generic instantiations. This paper presents an evaluation of the behaviour of refactoring tools on source code that defines or uses generics. We compare the behaviour of five refactoring tools on a well known refactoring, Extract Method, and its implementation for the JAVA language. We distill the lessons learned from our evaluation into requirements that have to be taken into account by refactoring tools in order to fully conform to this new language feature."
"Dig D,Batory D",Fourth Workshop on Refactoring Tools (WRT 2011),2011,,"Refactoring is the process of applying behavior-preserving transformations to a program with the objective of improving the program's design. A specific refactoring is identified by a name (e. g., Extract Method), a set of preconditions, and a set of transformations that need to be performed. Tool support for refactoring is essential because checking the preconditions of refactoring often requires nontrivial program analysis, and applying transformations may affect many locations throughout a program. In recent years, the emergence of light-weight programming methodologies such as Extreme Programming has generated a great amount of interest in refactoring, and refactoring support has become a required feature in today's IDEs. This workshop is a continuation of a series of previous workshops (ECOOP 2007, OOPSLA 2008 and 2009 - see http://refactoring.info/WRT) where researchers and developers of refactoring tools can meet and discuss recent ideas and work, and view tool demonstrations."
"Higo Y,Kamiya T,Kusumoto S,Inoue K",Refactoring support based on code clone analysis,2004,,"Software maintenance is the most expensive activity in software development. Many software companies spent a large amount of cost to maintain the existing software systems. In perfective maintenance, refactoring has often been applied to the software to improve the understandability and complexity. One of the targets of refactoring is code clone. A code clone is a code fragment in a source code that is identical or similar to another. In an actual software development process, code clones are introduced because of various reasons such as reusing code by `copy-and-paste' and so on. Code clones are one of the factors that make software maintenance difficult. In this paper, we propose a method which removes code clones from object oriented software by using existing refactoring patterns, especially ``Extract Method'' and ``Pull Up Method''. Then, we have implemented a refactoring supporting tool based on the proposed method. Finally, we have applied the tool to an open source program and actually perform refactoring."
"Mahmoud A,Niu N",Supporting requirements to code traceability through refactoring,2014,http://dx.doi.org/10.1007/s00766-013-0197-0,"In this paper, we hypothesize that the distorted traceability tracks of a software system can be systematically re-established through refactoring, a set of behavior-preserving transformations for keeping the system quality under control during evolution. To test our hypothesis, we conduct an experimental analysis using three requirements-to-code datasets from various application domains. Our objective is to assess the impact of various refactoring methods on the performance of automated tracing tools based on information retrieval. Results show that renaming inconsistently named code identifiers, using Rename Identifier refactoring, often leads to improvements in traceability. In contrast, removing code clones, using eXtract Method (XM) refactoring, is found to be detrimental. In addition, results show that moving misplaced code fragments, using Move Method refactoring, has no significant impact on trace link retrieval. We further evaluate Rename Identifier refactoring by comparing its performance with other strategies often used to overcome the vocabulary mismatch problem in software artifacts. In addition, we propose and evaluate various techniques to mitigate the negative impact of XM refactoring. An effective traceability sign analysis is also conducted to quantify the effect of these refactoring methods on the vocabulary structure of software systems."
"Silva D,Tsantalis N,Valente MT",Why We Refactor? Confessions of GitHub Contributors,2016,http://dx.doi.org/10.1145/2950290.2950305,"Refactoring is a widespread practice that helps developers to improve the maintainability and readability of their code. However, there is a limited number of studies empirically investigating the actual motivations behind specific refactoring operations applied by developers. To fill this gap, we monitored Java projects hosted on GitHub to detect recently applied refactorings, and asked the developers to ex- plain the reasons behind their decision to refactor the code. By applying thematic analysis on the collected responses, we compiled a catalogue of 44 distinct motivations for 12 well-known refactoring types. We found that refactoring activity is mainly driven by changes in the requirements and much less by code smells. Extract Method is the most versatile refactoring operation serving 11 different purposes. Finally, we found evidence that the IDE used by the developers affects the adoption of automated refactoring tools."
"Tavares CS,Ferreira F,Figueiredo E",A Systematic Mapping of Literature on Software Refactoring Tools,2018,http://dx.doi.org/10.1145/3229345.3229357,"Refactoring consists of improving the internal structure of the code without changing the external behavior of a software system. However, the task of refactoring is very costly in the development of an information system. Thus, many tools have been proposed to support refactoring the source code. In order to find tools cited in the literature, this work presents a Systematic Literature Mapping about refactoring. As a result, this paper summarizes the refactoring tools that have been published in the last 5 years in terms of the tool profiles developed, which programming languages have support for refactoring and which are the main refactoring strategies that are handled by tools. It has been identified that publications on refactoring have remained constant over the past 5 years. Also, most of the refactoring works describe tools, being they for systems written in the Java language, that perform code refactoring automatically and the main refactorings are: Move Method, Pull Up Method, Extract Class and Code Clone. Finally, we performed an analysis of the data returned by the DBLP library. As a result, it was observed that the papers returned by the DBLP have a high level of similarity with the other research bases studied."
"Cousot P,Cousot R,Logozzo F,Barnett M",An Abstract Interpretation Framework for Refactoring with Application to Extract Methods with Contracts,2012,http://dx.doi.org/10.1145/2398857.2384633,"Method extraction is a common refactoring feature provided by most modern IDEs. It replaces a user-selected piece of code with a call to an automatically generated method. We address the problem of automatically inferring contracts (precondition, postcondition) for the extracted method. We require the inferred contract: (a) to be valid for the extracted method (validity); (b) to guard the language and programmer assertions in the body of the extracted method by an opportune precondition (safety); (c) to preserve the proof of correctness of the original code when analyzing the new method separately (completeness); and (d) to be the most general possible (generality). These requirements rule out trivial solutions (e. g., inlining, projection, etc). We propose two theoretical solutions to the problem. The first one is simple and optimal. It is valid, safe, complete and general but unfortunately not effectively computable (except for unrealistic finiteness/decidability hypotheses). The second one is based on an iterative forward/backward method. We show it to be valid, safe, and, under reasonable assumptions, complete and general. We prove that the second solution subsumes the first. All justifications are provided with respect to a new, set-theoretic version of Hoare logic (hence without logic), and abstractions of Hoare logic, revisited to avoid surprisingly unsound inference rules. We have implemented the new algorithms on the top of two industrial-strength tools (CCCheck and the Microsoft Roslyn CTP). Our experience shows that the analysis is both fast enough to be used in an interactive environment and precise enough to generate good annotations."
"Charalampidou S,Ampatzoglou A,Chatzigeorgiou A,Gkortzis A,Avgeriou P",Identifying Extract Method Refactoring Opportunities Based on Functional Relevance,2017,http://dx.doi.org/10.1109/TSE.2016.2645572,"`Extract Method' is considered one of the most frequently applied and beneficial refactorings, since the corresponding Long Method smell is among the most common and persistent ones. Although Long Method is conceptually related to the implementation of diverse functionalities within a method, until now, this relationship has not been utilized while identifying refactoring opportunities. In this paper we introduce an approach (accompanied by a tool) that aims at identifying source code chunks that collaborate to provide a specific functionality, and propose their extraction as separate methods. The accuracy of the proposed approach has been empirically validated both in an industrial and an open-source setting. In the former case, the approach was capable of identifying functionally related statements within two industrial long methods (approx. 500 LoC each), with a recall rate of 93 percent. In the latter case, based on a comparative study on open-source data, our approach ranks better compared to two well-known techniques of the literature. To assist software engineers in the prioritization of the suggested refactoring opportunities the approach ranks them based on an estimate of their fitness for extraction. The provided ranking has been validated in both settings and proved to be strongly correlated with experts' opinion."
"Silva IP,Alves EL,Machado PD",Can Automated Test Case Generation Cope With Extract Method Validation?,2018,http://dx.doi.org/10.1145/3266237.3266274,"Refactoring often requires regression testing to check whether changes applied to the code have preserved its behavior. It is usually tricky to create an effective test suite for this task, since refactoring is not often applied in isolated steps. Rather refactoring edits may be combined with other edits in the code. In this sense, test case generation can contributed to this task by systematically analyzing the code and providing a wide range of test cases that address different constructions in the code. However, a number of studies in the literature have found that current tools can be ineffective regarding fault detection. In this paper, we present an empirical study that applies the Randoop and Evosuite tools for generating regression test suites, focusing on detecting Extract Method faults. Based on the study results, we identify factors that may influence on the performance of the tools for effectively testing the edits. To validate our findings, we present a set of regression models that associate the presence of these factors with the capability of the test suite detect faults related to the refactoring edit."
"Meananeatra P,Rongviriyapanish S,Apiwattanapong T",Refactoring Opportunity Identification Methodology for Removing Long Method Smells and Improving Code Analyzability,2018,http://dx.doi.org/10.1587/transinf.2017KBP0026,"An important step for improving software analyzability is applying refactorings during the maintenance phase to remove bad smells, especially the long method bad smell. Long method bad smell occurs most frequently and is a root cause of other bad smells. However, no research has proposed an approach to repeating refactoring identification, suggestion, and application until all long method bad smells have been removed completely without reducing software analyzability. This paper proposes an effective approach to identifying refactoring opportunities and suggesting an effective refactoring set for complete removal of long method bad smell without reducing code analyzability. This approach, called the long method remover or LMR, uses refactoring enabling conditions based on program analysis and code metrics to identify four refactoring techniques and uses a technique embedded in JDeodorant to identify extract method. For effective refactoring set suggestion, LMR uses two criteria: code analyzability level and the number of statements impacted by the refactorings. LMR also uses side effect analysis to ensure behavior preservation. To evaluate LMR, we apply it to the core package of a real world Java application. Our evaluation criteria are 1) the preservation of code functionality, 2) the removal rate of long method characteristics, and 3) the improvement on analyzability. The result showed that the methods that apply suggested refactoring sets can completely remove long method bad smell, still have behavior preservation, and have not decreased analyzability. It is concluded that LMR meets the objectives in almost all classes. We also discussed the issues we found during evaluation as lesson learned."
"Mahmoudi M,Nadi S,Tsantalis N",Are Refactorings to Blame? An Empirical Study of Refactorings in Merge Conflicts,2019,,"With the rise of distributed software development, branching has become a popular approach that facilitates collaboration between software developers. One of the biggest challenges that developers face when using multiple development branches is dealing with merge conflicts. Conflicts occur when inconsistent changes happen to the code. Resolving these conflicts can be a cumbersome task as it requires prior knowledge about the changes in each of the development branches. A type of change that could potentially lead to complex conflicts is code refactoring. Previous studies have proposed techniques for facilitating conflict resolution in the presence of refactorings. However, the magnitude of the impact that refactorings have on merge conflicts has never been empirically evaluated. In this paper, we perform an empirical study on almost 3,000 well-engineered open-source Java software repositories and investigate the relation between merge conflicts and 15 popular refactoring types. Our results show that refactoring operations are involved in 22% of merge conflicts, which is remarkable taking into account that we investigated a relatively small subset of all possible refactoring types. Furthermore, certain refactoring types, such as EXTRACT METHOD, tend to be more problematic for merge conflicts. Our results also suggest that conflicts that involve refactored code are usually more complex, compared to conflicts with no refactoring changes."
"Brito A,Hora A,Tulio Valente M",Towards a catalog of composite refactorings,,http://dx.doi.org/10.1002/smr.2530,"Catalogs of refactoring have key importance in software maintenance and evolution, since developers rely on such documents to understand and perform refactoring operations. Furthermore, these catalogs constitute a reference guide for communication between practitioners since they standardize a common refactoring vocabulary. Fowler's book describes the most popular catalog of refactorings, which documents single and well-known refactoring operations. However, sometimes, refactorings are composite transformations, that is, a sequence of refactorings is performed over a given program element. For example, a sequence of Extract Method operations (a single refactoring) can be performed over the same method, in one or in multiple commits, to simplify its implementation, therefore, leading to a Method Decomposition operation (a composite refactoring). In this paper, we propose and document a catalog with eight composite refactorings. We also implement a set of scripts to mine composite refactorings by preprocessing the results of refactoring detection tools. Using such scripts, we search for composites in a representative refactoring oracle with hundreds of confirmed single refactoring operations. Next, to complement this first study, we also search for composites in the full history of 10 well-known open-source projects. We characterize the detected composite refactorings, under dimensions such as size and location. We conclude by addressing the applications and implications of the proposed catalog."
"Traini L,Di Pompeo D,Tucci M,Lin B,Scalabrino S,Bavota G,Lanza M,Oliveto R,Cortellessa V",How Software Refactoring Impacts Execution Time,2022,http://dx.doi.org/10.1145/3485136,"Refactoring aims at improving the maintainability of source code without modifying its external behavior. Previous works proposed approaches to recommend refactoring solutions to software developers. The generation of the recommended solutions is guided by metrics acting as proxy for maintainability (e.g., number of code smells removed by the recommended solution). These approaches ignore the impact of the recommended refactorings on other non-functional requirements, such as performance, energy consumption, and so forth. Little is known about the impact of refactoring operations on non-functional requirements other than maintainability. We aim to fill this gap by presenting the largest study to date to investigate the impact of refactoring on software performance, in terms of execution time. We mined the change history of 20 systems that defined performance benchmarks in their repositories, with the goal of identifying commits in which developers implemented refactoring operations impacting code components that are exercised by the performance benchmarks. Through a quantitative and qualitative analysis, we show that refactoring operations can significantly impact the execution time. Indeed, none of the investigated refactoring types can be considered ``safe'' in ensuring no performance regression. Refactoring types aimed at decomposing complex code entities (e.g., Extract Class/Interface, Extract Method) have higher chances of triggering performance degradation, suggesting their careful consideration when refactoring performance-critical code."
"Kaya M,Fawcett JW",Identification of Extract Method Refactoring Opportunities through Analysis of Variable Declarations and Uses,2017,http://dx.doi.org/10.1142/S0218194017500036,"Software development is a continuous process that usually starts with analyzing the system requirements and proceeds with design, implementation, testing, and maintenance. Regardless of how good an initial design was achieved, quality of source code tends to decay throughout the development process as software evolves. One of the main contributing factors to this degradation of initial quality can be considered as maintenance operations, for instance to enhance performance or other attributes of the system or to fix newly discovered bugs. For such large software systems, development process also requires reusing existing components which may have been implemented by others. Hence, a comprehensible piece of source code, e.g. one that conveys its message about what it is trying to do easily with understandable and modular implementation, significantly reduces time and effort not only for the implementation phase of the development lifecycle; but also for testing and maintenance phases. In other words, while software decay is inevitable, software comprehension plays a determining role in the total cost and effectiveness of both implementation phase and maintenance phase. Therefore, developers should strive to create software components with modular structure and clearer implementation to reduce the development cost. In this paper, we are interested in finding ways to successfully decompose long methods ( those with poor initial implementation and/or decayed overtime) into smaller, more comprehensible and readable ones. This decomposition process is known as extract method refactoring and helps to reduce the overall cost of development. Most of the existing refactoring tools require users to select the code fragments that need to be extracted. We introduce a novel technique for this refactoring. This technique seeks refactoring opportunities based on variable declarations and uses confining fully extractable code regions without any user intervention. We implemented this technique as an analysis and visualization tool to help a user identify candidate code fragments to be extracted as separate methods. With this automation tool, developers do not have to manually inspect a foreign"
"Silva D,Nunes I,Terra R",Investigating Code Quality Tools in the Context of Software Engineering Education,2017,http://dx.doi.org/10.1002/cae.21793,"A key issue involved with software engineering education consists of how to guarantee that adequate software engineering principles are being followed at the code level, thus reinforcing that students produce high-quality code. Reviewing and grading student projects to verify whether they followed such principles is a time-consuming task, since this typically involves manual code inspection. In this paper, we exploit code quality tools and metrics to automatically assess student projects with respect to methods with many responsibilities (i.e., where the Extract Method refactoring should be applied), and evaluate their effectiveness. We conducted a study using two sets of student projects, developed in two academic semesters. Our results indicate that, to reduce the effort required to grade projects, two traditional code metrics, namely method lines of code and number of statements, perform best, and other metrics can be selected according to the system being implemented. (C) 2017 Wiley Periodicals, Inc."
"Ouni A,Kessentini M,Sahraoui H,Inoue K,Deb K",Multi-Criteria Code Refactoring Using Search-Based Software Engineering: An Industrial Case Study,2016,http://dx.doi.org/10.1145/2932631,"One of the most widely used techniques to improve the quality of existing software systems is refactoring-the process of improving the design of existing code by changing its internal structure without altering its external behavior. While it is important to suggest refactorings that improve the quality and structure of the system, many other criteria are also important to consider, such as reducing the number of code changes, preserving the semantics of the software design and not only its behavior, and maintaining consistency with the previously applied refactorings. In this article, we propose a multi-objective search-based approach for automating the recommendation of refactorings. The process aims at finding the optimal sequence of refactorings that (i) improves the quality by minimizing the number of design defects, (ii) minimizes code changes required to fix those defects, (iii) preserves design semantics, and (iv) maximizes the consistency with the previously code changes. We evaluated the efficiency of our approach using a benchmark of six open-source systems, 11 different types of refactorings (move method, move field, pull up method, pull up field, push down method, push down field, inline class, move class, extract class, extract method, and extract interface) and six commonly occurring design defect types (blob, spaghetti code, functional decomposition, data class, shotgun surgery, and feature envy) through an empirical study conducted with experts. In addition, we performed an industrial validation of our technique, with 10 software engineers, on a large project provided by our industrial partner. We found that the proposed refactorings succeed in preserving the design coherence of the code, with an acceptable level of code change score while reusing knowledge from recorded refactorings applied in the past to similar contexts."
"Saborido R,Ferrer J,Chicano F,Alba E",Automatizing Software Cognitive Complexity Reduction,2022,http://dx.doi.org/10.1109/ACCESS.2022.3144743,"Software plays a central role in our life nowadays. We use it almost anywhere, at any time, and for everything: to browse the Internet, to check our emails, and even to access critical services such as health monitoring and banking. Hence, its reliability and general quality is critical. As software increases in complexity, developers spend more time fixing bugs or making code work rather than designing or writing new code. Thus, improving software understandability and maintainability would translate into an economic relief over the total cost of a project. Different cognitive complexity measures have been proposed to quantify the understandability of a piece of code and, therefore, its maintainability. However, the cognitive complexity metric provided by SonarSource and integrated in SonarCloud and SonarQube is quickly spreading in the software industry due to the popularity of these well-known static code tools for evaluating software quality. Despite SonarQube suggests to keep method's cognitive complexity no greater than 15, reducing method's complexity is challenging for a human programmer and there are no approaches to assist developers on this task. We model the cognitive complexity reduction of a method as an optimization problem where the search space contains all sequences of Extract Method refactoring opportunities. We then propose a novel approach that searches for feasible code extractions allowing developers to apply them, all in an automated way. This will allow software developers to make informed decisions while reducing the complexity of their code. We evaluated our approach over 10 open-source software projects and was able to fix 78% of the 1,050 existing cognitive complexity issues reported by SonarQube. We finally discuss the limitations of the proposed approach and provide interesting findings and guidelines for developers."
"Bibiano AC,Assuncao WK,Coutinho D,Santos K,Soares V,Gheyi R,Garcia A,Fonseca B,Ribeiro M,Oliveira D,Barbosa C,Marques JL,Oliveira A",Look Ahead! Revealing Complete Composite Refactorings and their Smelliness Effects,2021,http://dx.doi.org/10.1109/ICSME52107.2021.00033,"Recent studies have revealed that developers often apply composite refactorings (or, simply, composites). A composite consists of two or more interrelated refactorings applied together. Previous studies investigated the effect of composites on code smells. A composite is considered ``complete'' whenever it completely removes one target code smell. They proposed descriptions of complete composites with recommendations to remove certain code smell types, such as Long Methods and Feature Envies. These studies also present different recommendations to remove the same code smell type. However, these studies: (i) are limited to composites only consisting of a small subset of Fowler's refactoring types, (ii) do not detail the scenarios in which each recommendation can be applied to remove the code smell, and (iii) fail in reporting possible side effects of the described composites, such as adversely introducing certain smell types. This paper aims to cover these limitations by performing a systematic analysis of 618 complete composites on removing four common smell types identified in 20 software projects. Our results indicated that: (i) 64% complete composites consisted of refactoring types not covered by existing descriptions of complete composites, and (ii) 36% complete composites formed by Extract Methods can introduce Feature Envies and Intensive Couplings. This information is not documented by existing descriptions, and it can alert developers about alternatives to remove Feature Envy, mainly in methods that are fully envious. These results suggest existing descriptions of complete composites should be either revisited or enhanced to explicitly highlight known side effects. We present a catalog of composites with details about side effects, recommendations to remove or minimize them, and some scenarios in which each recommendation can be applied to remove the code smell. Our catalog can be useful to improve existing tooling support for refactorings, such as IDEs, informing about possible side effects when refactorings are composed."
"Hatano T,Matsuo A",Removing Code Clones from Industrial Systems Using Compiler Directives,2017,http://dx.doi.org/10.1109/ICPC.2017.4,"Refactoring of code clones is an effective method for improving software maintainability. Existing studies have proposed automated techniques and tools for refactoring. However, it is difficult to apply refactoring to our industrial systems in practice because of three main reasons. First, we have many industrial systems written in COBOL which requires a particular refactoring method compared with current techniques because Type-2 clones in COBOL are generated by renaming parts of identifiers. Second, nested clones must be refactored, in which an instance of a clone set is contained within an instance of another clone set. They also make it difficult to estimate the reduction size by refactoring. Third, refactoring requires testing which is time-consuming and laborious. To overcome these problems, we developed an approach for refactoring of Type-2 clones in COBOL programs. Our approach identifies actual refactorable clone sets and includes a string comparison technique to parameterize partial differences in identifier names. The clone sets are extracted as shared code fragments and transformed into the refactored code using compiler directives. It is easy to confirm that refactoring using compiler directives preserves program behavior, because they do not change program structure. We also provide a method that makes it possible to refactor nested clones by ordering their refactoring. This method enables to estimate how many lines can be reduced by refactoring. We applied the approach to four industrial systems to assess how many lines can be reduced. The results show that the lines could be reduced by 10 to 15% and one system was reduced by 27%. We also discuss the parameter number required for our refactoring approach."
"Cui D,Wang S,Luo Y,Li X,Dai J,Wang L,Li Q",RMove: Recommending Move Method Refactoring Opportunities using Structural and Semantic Representations of Code,2022,http://dx.doi.org/10.1109/ICSME55016.2022.00033,"Incorrect placement of methods within classes is a typical code smell called Feature Envy, which causes additional maintenance and cost during evolution. To remove this design flaw, several Move Method refactoring tools have been proposed. To the best of our knowledge, state-of-the-art related techniques can be broadly divided into two categories: the first line is non-machine-learning-based approaches built on software measurement, while the selection and thresholds of software metrics heavily rely on expert knowledge. The second line is machine learning-based approaches, which suggest Move Method refactoring by learning to extract features from code information. However, most approaches in this line treat different forms of code information identically, disregarding their significant variation on data analysis. In this paper, we propose an approach to recommend Move Method refactoring named RMove by automatically learning structural and semantic representation from code fragment respectively. We concatenate these representations together and further train the machine learning classifiers to guide the movement of method to suitable classes. We evaluate our approach on two publicly available datasets. The results show that our approach outperforms three state-of-the-art refactoring tools including PathMove, JDeodorant, and JMove in effectiveness and usefulness. The results also unveil useful findings and provide new insights that benefit other types of feature envy refactoring techniques."
"Tsantalis N,Chatzigeorgiou A",Identification of refactoring opportunities introducing polymorphism,2010,http://dx.doi.org/10.1016/j.jss.2009.09.017,"Polymorphism is one of the most important features offered by object-oriented programming languages, since it allows to extend/modify the behavior of a class without altering its source code, in accordance to the Open/Closed Principle. However, there is a lack of methods and tools for the identification of places in the code of an existing system that could benefit from the employment of polymorphism. In this paper we propose a technique that extracts refactoring suggestions introducing polymorphism. The approach ensures the behavior preservation of the code and the applicability of the refactoring suggestions based on the examination of a set of preconditions. (C) 2009 Elsevier Inc. All rights reserved."
"Eilertsen AM,Bagge AH,Stolz V",Safer Refactorings,2016,http://dx.doi.org/10.1007/978-3-319-47166-2_36,"Refactorings often require semantic correctness conditions that amount to software model checking. However, IDEs such as Eclipse's Java Development Tools implement far simpler checks on the structure of the code. This leads to the phenomenon that a seemingly innocuous refactoring can change the behaviour of the program. In this paper we demonstrate our technique of introducing runtime checks for two particular refactorings for the Java programming language: Extract And Move Method, and Extract Local Variable. These checks can, in combination with unit tests, detect changed behaviour and allow identification of which specific refactoring step introduced the deviant behaviour."
"Lin C,Ju Q,YuMing Z,Peng W,BaoWen X",Identifying extract class refactoring opportunities for internetware,2014,http://dx.doi.org/10.1007/s11432-013-5024-1,"The quality of internetware software is significantly associated with class structure. As software evolves, changes often introduce many unrelated responsibilities to the same classes or distribute tightly-related methods in different classes. These changes make the classes difficult to understand and maintain. Extract class refactoring is an effective technique to improve the quality of software structure by decomposing unrelated methods in one class to create new classes or extracting tightly-related methods from different classes. In this paper, we propose a novel approach for class extraction from internetware source codes. This approach leverages a community structure detection technique to partition software into clusters and extracts classes from the resulting clusters. Our experimental results, which investigate the public well-known internetware PKUAS, indicate that: (1) the proposed approach is much faster than existing search-based clustering approaches (Hill-climbing and Genetic algorithm) and is thus applicable for large-scale internetware; (2) the proposed approach can identify meaningful class extractions for internetware; and (3) Extract Class refactoring candidates identified by the proposed approach significantly improve class cohesion of internetware."
Alzahrani M,Measuring Class Cohesion Based on Client Similarities Between Method Pairs: An Improved Approach That Supports Refactoring,2020,http://dx.doi.org/10.1109/ACCESS.2020.3046109,"Class cohesion is an important quality attribute that has an impact on other quality attributes such understandability, testability, and maintainability. Therefore, classes with low cohesion should be refactored in order to improve their overall qualities. Many cohesion metrics have been introduced in the literature to automatically assess the quality of the class and support refactoring activities. Most existing metrics measure the class cohesion based on how the methods of a class are internally related to each other, while a few metrics measure the class cohesion based on how the methods are externally used by the clients of the class. Unfortunately, the existing client-based cohesion metrics cannot automatically support refactoring techniques such as the Extract Class refactoring. Therefore, this article proposes a new client-based cohesion metric that can be used to automatically identify Extract Class refactoring opportunities. The proposed metric is theoretically evaluated by proving the compliance of the metric to the mathematical cohesion properties, while it is empirically evaluated by conducting a large case study on three systems to compare the metric with other cohesion metrics. Finally, the paper introduces and evaluates an Extract Class refactoring approach based the proposed cohesion metric."
"Han AR,Bae DH",Dynamic profiling-based approach to identifying cost-effective refactorings,2013,http://dx.doi.org/10.1016/j.infsof.2012.12.002,"Context: Object-oriented software undergoes continuous changes-changes often made without consideration of the software's overall structure and design rationale. Hence, over time, the design quality of the software degrades causing software aging or software decay. Refactoring offers a means of restructuring software design to improve maintainability. In practice, efforts to invest in refactoring are restricted; therefore, the problem calls for a method for identifying cost-effective refactorings that efficiently improve maintainability. Cost-effectiveness of applied refactorings can be explained as maintainability improvement over invested refactoring effort (cost). For the system, the more cost-effective refactorings are applied, the greater maintainability would be improved. There have been several studies of supporting the arguments that changes are more prone to occur in the pieces of codes more frequently utilized by users; hence, applying refactorings in these parts would fast improve maintainability of software. For this reason, dynamic information is needed for identifying the entities involved in given scenarios/functions of a system, and within these entities, refactoring candidates need to be extracted. Objective: This paper provides an automated approach to identifying cost-effective refactorings using dynamic information in object-oriented software. Method: To perform cost-effective refactoring, refactoring candidates are extracted in a way that reduces dependencies; these are referred to as the dynamic information. The dynamic profiling technique is used to obtain the dependencies of entities based on dynamic method calls. Based on those dynamic dependencies, refactoring-candidate extraction rules are defined, and a maintainability evaluation function is established. Then, refactoring candidates are extracted and assessed using the defined rules and the evaluation function, respectively. The best refactoring (i.e., that which most improves maintainability) is selected from among refactoring candidates, then refactoring candidate extraction and assessment are re-performed to select the next refactoring, and the refactoring identification process is iterated until no more refactoring candidates for improving maintainability are found. Results: We evaluate our proposed approach in three open-source projects. The first results show that dynamic information is helpful in identifying cost-effective refactorings that fast improve maintainability; and, considering dynamic information in addition to static information provides even more opportunities to identify cost-effective refactorings. The second results show that dynamic information is helpful in extracting refactoring candidates in the classes where real changes had occurred; in addition, the results also offer the promising support for the contention that using dynamic information helps to extracting refactoring candidates from highly-ranked frequently changed classes. Conclusion: Our proposed approach helps to identify cost-effective refactorings and supports an automated refactoring identification process. (C) 2012 Elsevier B.V. All rights reserved."
"Kaur G,Singh B",Improving the Quality of Software by Refactoring,2017,,"Software code management has become another key skill required by software architects and software developers. Size of software increases with increase in count of features in software. Code refactoring is process of reducing code maintenance cost. It is achieved by many different techniques like extract, move methods, fields or classes in code. In this research we focused on improving the maintainability of the code by looking into the different refactoring techniques and improving upon them. We proposed an algorithm to improve the refactoring process which results in higher maintainability. To look into the validity of our proposed algorithm, we have used Junit and reffinder to analyse the code and generate the result metrics. We have observed the effectiveness of our work by comparing the different code maintainability indexes generated by the tool. In our research we have examined four releases of the software project for code refactoring and maintainability. Adding some extra features and using enhanced refactoring techniques measuring the code metrics and comparing the results of current releases with the previous releases."
Al Dallal J,Identifying refactoring opportunities in object-oriented code: A systematic literature review,2015,http://dx.doi.org/10.1016/j.infsof.2014.08.002,"Context: Identifying refactoring opportunities in object-oriented code is an important stage that precedes the actual refactoring process. Several techniques have been proposed in the literature to identify opportunities for various refactoring activities. Objective: This paper provides a systematic literature review of existing studies identifying opportunities for code refactoring activities. Method: We performed an automatic search of the relevant digital libraries for potentially relevant studies published through the end of 2013, performed pilot and author-based searches, and selected 47 primary studies (PSs) based on inclusion and exclusion criteria. The PSs were analyzed based on a number of criteria, including the refactoring activities, the approaches to refactoring opportunity identification, the empirical evaluation approaches, and the data sets used. Results: The results indicate that research in the area of identifying refactoring opportunities is highly active. Most of the studies have been performed by academic researchers using nonindustrial data sets. Extract Class and Move Method were found to be the most frequently considered refactoring activities. The results show that researchers use six primary existing approaches to identify refactoring opportunities and six approaches to empirically evaluate the identification techniques. Most of the systems used in the evaluation process were open-source, which helps to make the studies repeatable. However, a relatively high percentage of the data sets used in the empirical evaluations were small, which limits the generality of the results. Conclusions: It would be beneficial to perform further studies that consider more refactoring activities, involve researchers from industry, and use large-scale and industrial-based systems. (C) 2014 Elsevier B.V. All rights reserved."
"Tian F,Liang P,Babar MA",How Developers Discuss Architecture Smells? An Exploratory Study on Stack Overflow,2019,http://dx.doi.org/10.1109/ICSA.2019.00018,"Architecture Smells (ASs) are design decisions that can have significant negative effects on a system's quality attributes such as reusability and testability. ASs are focused on higher level of software systems than code smells, which are implementation-level constructs. ASs can have much wider impact on a system than code smells. However, ASs usually receive less attention than code smells in both research and practice. We have conducted an exploratory study of developers' conception of ASs by analyzing related discussions in Stack Overflow. We used 14 ASs related terms to search the relevant posts in Stack Overflow and extracted 207 posts. We used Grounded Theory method for analyzing the extracted posts about developers' description of ASs, causes of ASs, approaches and tools for detecting and refactoring ASs, quality attributes affected by ASs, and difficulties in detecting and refactoring ASs. Our findings show that: (1) developers often describe ASs with some general terms; (2) ASs are mainly caused by violating architecture patterns, design principles, or misusing architecture antipatterns; (3) there is a lack of dedicated tools for detecting and refactoring ASs; (4) developers mainly concern about the maintainability and performance of systems affected by ASs; and (5) the inability to quantify the cost and benefit as well as the lack of approaches and tools makes detecting and refactoring ASs difficult."
"Sharma T,Murthy PV",ESA: The Exclusive-Similarity Algorithm for Identifying Extract-class Refactoring Candidates Automatically,2014,http://dx.doi.org/10.1145/2590748.2590763,"Refactoring has become an essential part of software development process especially for large and long lasting projects. Extract-class is one of the vital refactorings that is used to improve cohesion of a class by splitting large in-cohesive classes into more cohesive ones. Providing automated means of identifying opportunities for extract-class refactoring could make the software maintenance efficient. In this paper, a novel algorithm viz. ESA (''Exclusive-Similarity'' Algorithm) is proposed to identify extract-class refactoring candidates automatically. The algorithm proposes new metrics viz. Exclusive-Similarity metric (ESM), Cohesion among Method-Clusters, (CMC) and Method-Similarity with Attribute-Clusters (MSAC). The proposed algorithm has been realized into a tool as an add-in to Visual Studio and the tool is exercised with 3 open-source projects to demonstrate applicability."
"Wang Y,Yu H,Zhu Z,Zhang W,Zhao Y",Automatic Software Refactoring via Weighted Clustering in Method-Level Networks,2018,http://dx.doi.org/10.1109/TSE.2017.2679752,"In this study, we describe a system-level multiple refactoring algorithm, which can identify the move method, move field, and extract class refactoring opportunities automatically according to the principle of ``high cohesion and low coupling.'' The algorithm works by merging and splitting related classes to obtain the optimal functionality distribution from the system-level. Furthermore, we present a weighted clustering algorithm for regrouping the entities in a system based on merged method-level networks. Using a series of preprocessing steps and preconditions, the ``bad smells'' introduced by cohesion and coupling problems can be removed from both the non-inheritance and inheritance hierarchies without changing the code behaviors. We rank the refactoring suggestions based on the anticipated benefits that they bring to the system. Based on comparisons with related research and assessing the refactoring results using quality metrics and empirical evaluation, we show that the proposed approach performs well in different systems and is beneficial from the perspective of the original developers. Finally, an open source tool is implemented to support the proposed approach."
"Sato F,Ikegami A,Ishio T,Shimari K,Matsumoto K",Comparing Execution Traces of Jupyter Notebook for Checking Correctness of Refactoring,2022,http://dx.doi.org/10.1109/IWSC55060.2022.00019,"Jupyter Notebook is a popular tool for writing data analysis programs. Prior work showed that Jupyter Notebook users often duplicate their python code to try their hypothesis quickly. While such code clones can be removed by Extract Function refactoring later, users have to check that the output of a notebook is unaffected by the refactoring. However, users may not be able to compare execution results of a notebook before and after refactoring because non-textual output in Jupyter Notebook are fragile; for example, each of executions produce non-identical graphical images even though they look the same. To address this issue, we propose a method to automatically compare API calls to execute a Jupyter Notebook in addition to the textual output, while ignoring non-textual output. Our key assumption is that the same API calls with the same parameters produce the same results even if their details are non-identical. To demonstrate the effectiveness of the approach, we implemented an automatic tool for Jupyter Notebook that extracts a function from code clones and automatically checks the correctness. Using the tool, we have extracted functions from 3,995 cells in 520 Jupyter Notebook files. 142 out of 520 Notebook files are executable. Our tool compared API calls to check the correctness for 88 Notebook files, while a simple textual comparison could check 22 Notebook files."
"Meng N,Hua L,Kim M,McKinley KS",Does Automated Refactoring Obviate Systematic Editing?,2015,http://dx.doi.org/10.1109/ICSE.2015.58,"When developers add features and fix bugs, they often make systematic edits-similar edits to multiple locations. Systematic edits may indicate that developers should instead refactor to eliminate redundancy. This paper explores this question by designing and implementing a fully automated refactoring tool called RASE, which performs clone removal. RASE (1) extracts common code guided by a systematic edit; (2) creates new types and methods as needed; (3) parameterizes differences in types, methods, variables, and expressions; and (4) inserts return objects and exit labels based on control and data flow. To our knowledge, this functionality makes RASE the most advanced refactoring tool for automated clone removal. We evaluate RASE with real-world systematic edits and compare to method based clone removal. RASE successfully performs clone removal in 30 of 56 method pairs (n=2) and 20 of 30 method groups (n >= 3) with systematic edits. We find that scoping refactoring based on systematic edits (58%), rather than the entire method (33%), increases the applicability of automated clone removal. Automated refactoring is not feasible in the other 42% cases, which indicates that automated refactoring does not obviate the need for systematic editing."
"Ghannem A,El Boussaidi G,Kessentini M",Model refactoring using examples: a search-based approach,2014,http://dx.doi.org/10.1002/smr.1644,"One of the important challenges in model-driven engineering is how to improve the quality of the models' design in order to help designers understand them. Refactoring represents an efficient technique to improve the quality of a design while preserving its behavior. Most of existing work on model refactoring relies on declarative rules to detect refactoring opportunities and to apply the appropriate refactorings. However, a complete specification of refactoring opportunities requires a huge number of rules. In this paper, we consider the refactoring mechanism as a combinatorial optimization problem where the goal is to find good refactoring suggestions starting from a small set of refactoring examples applied to similar contexts. Our approach, named model refactoring by example, takes as input an initial model to refactor, a set of structural metrics calculated on both initial model and models in the base of examples, and a base of refactoring examples extracted from different software systems and generates as output a sequence of refactorings. A solution is defined as a combination of refactoring operations that should maximize as much as possible the structural similarity based on metrics between the initial model and the models in the base of examples. A heuristic method is used to explore the space of possible refactoring solutions. To this end, we used and adapted a genetic algorithm as a global heuristic search. The validation results on different systems of real-world models taken from open-source projects confirm the effectiveness of our approach. Copyright (C) 2014 John Wiley & Sons, Ltd."
"Alzahrani M,Alqithami S",An External Client-Based Approach for the Extract Class Refactoring: A Theoretical Model and an Empirical Approach,2020,http://dx.doi.org/10.3390/app10176038,"A commonly observed ambiguity of a class is simply a reflection of multiple methods' implementation within an individual class. The process of Extract Class refactoring is, therefore, used to separate the different responsibilities of a class into different classes. A major limitation in existing approaches of the Extract Class refactoring is based on factors that are internal to the class, i.e., structural and semantic relationships between methods, in order to identify and separate the responsibilities of the class which are inadequate in many cases. Thus, we propose a novel approach that exploits the clients of the class to support the Extract Class refactoring. The importance of this approach lies in its usefulness to support existing approaches since it involves factors external to the class, i.e., the clients. Moreover, an extensive empirical evaluation is presented to support the proposed method through the utilization of real classes selected from two open source systems. The result shows the potential of our proposed approach and usefulness that leads to an improvement in the quality of the considered classes."
"Caldeira J,Abreu FB,Cardoso J,dos Reis JP",Unveiling process insights from refactoring practices,2022,http://dx.doi.org/10.1016/j.csi.2021.103587,"Context: Software comprehension and maintenance activities, such as refactoring, are said to be negatively impacted by software complexity. The methods used to measure software product and processes complexity have been thoroughly debated in the literature. However, the discernment about the possible links between these two dimensions, particularly on the benefits of using the process perspective, has a long journey ahead. Objective: To improve the understanding of the liaison of developers' activities and software complexity within a refactoring task, namely by evaluating if process metrics gathered from the IDE, using process mining methods and tools, are suitable to accurately classify different refactoring practices and the resulting software complexity. Method: We mined source code metrics from a software product after a quality improvement task was given in parallel to (117) software developers, organized in (71) teams. Simultaneously, we collected events from their IDE work sessions (320) and used process mining to model their processes and extract the correspondent metrics. Results: Most teams using a plugin for refactoring (JDeodorant) reduced software complexity more effectively and with simpler processes than the ones that performed refactoring using only Eclipse native features. We were able to find moderate correlations (approximate to 43%) between software cyclomatic complexity and process cyclomatic complexity. Using only process driven metrics, we computed approximate to 30,000 models aiming to predict the type of refactoring method (automatic or manual) teams had used and the expected level of software cyclomatic complexity reduction after their work sessions. The best models found for the refactoring method and cyclomatic complexity level predictions, had an accuracy of 92.95% and 94.36%, respectively. Conclusions: We have demonstrated the feasibility of an approach that allows building cross-cutting analytical models in software projects, such as the one we used for detecting manual or automatic refactoring practices. Events from the development tools and support activities can be collected, transformed, aggregated, and analyzed with fewer privacy concerns or technical constraints than source code-driven metrics. This makes our approach agnostic to programming languages, geographic location, or development practices, making it suitable for challenging contexts, such as, in modern global software development where many projects adopt agile methodologies, and low/no code platforms. Initial findings are encouraging, and lead us to suggest practitioners may use our method in other development tasks, such as, defect analysis and unit or integration tests."
"Fokaefs M,Tsantalis N,Stroulia E,Chatzigeorgiou A",Identification and application of Extract Class refactorings in object-oriented systems,2012,http://dx.doi.org/10.1016/j.jss.2012.04.013,"Refactoring is recognized as an essential practice in the context of evolutionary and agile software development. Recognizing the importance of the practice, modern IDEs provide some support for low-level refactorings. A notable exception in the list of supported refactorings is the ``Extract Class'' refactoring. which is conceived to simplify large, complex, unwieldy and less cohesive classes. In this work, we describe a method and a tool, implemented as an Eclipse plugin, designed to fulfill exactly this need. Our method involves three steps: (a) recognition of Extract Class opportunities. (b) ranking of the identified opportunities in terms of the improvement each one is anticipated to bring about to the system design, and (c) fully automated application of the refactoring chosen by the developer. The first step relies on an agglomerative clustering algorithm, which identifies cohesive sets of class members within the system classes. The second step relies on the Entity Placement metric as a measure of design quality. Through a set of experiments we have shown that the tool is able to identify and extract new classes that developers recognize as ``coherent concepts'' and improve the design quality of the underlying system. (C) 2012 Elsevier Inc. All rights reserved."
"Hegedus P,Kadar I,Ferenc R,Gyimothy T",Empirical evaluation of software maintainability based on a manually validated refactoring dataset,2018,http://dx.doi.org/10.1016/j.infsof.2017.11.012,"Context: Refactoring is a technique for improving the internal structure of software systems. It has a solid theoretical background while being used in development practice also. However, we lack empirical research results on the real effect of code refactoring and its application. Objective: This paper presents a manually validated subset of a previously published dataset containing the refactorings extracted by the RefFinder tool, code metrics, and maintainability of 7 open-source systems. We found that RefFinder had around 27% overall average precision on the subject systems, thus our manually validated subset has substantial added value. Using the dataset, we studied several aspects of the refactored and non-refactored source code elements (classes and methods), like the differences in their maintainability and source code metrics. Method: We divided the source code elements into a group containing the refactored elements and a group with non-refactored elements. We analyzed the elements' characteristics in these groups using correlation analysis, Mann-Whitney U test and effect size measures. Results: Source code elements subjected to refactorings had significantly lower maintainability than elements not affected by refactorings. Moreover, refactored elements had significantly higher size related metrics, complexity, and coupling. Also these metrics changed more significantly in the refactored elements. The results are mostly in line with our previous findings on the not validated dataset, with the difference that clone metrics had no strong connection with refactoring. Conclusions: Compared to the preliminary analysis using a not validated dataset, the manually validated dataset led to more significant results, which suggests that developers find targets for refactorings based on some internal quality properties of the source code, like their size, complexity or coupling, but not clone related metrics as reported in our previous studies. They do not just use these properties for identifying targets, but also control them with refactorings."
"De Lucia A,Oliveto R,Vorraro L",Using Structural and Semantic Metrics to Improve Class Cohesion,2008,http://dx.doi.org/10.1109/ICSM.2008.4658051,"Several refactoring methods have been proposed in the literature to improve the cohesion of classes. Very often, refactoring operations are guided by cohesion metrics based on the structural information of the source code, such as attribute references in methods. In this paper we present a novel approach to guide the Extract Class refactoring [13], taking into account structural and semantic cohesion metrics. The proposed approach has been evaluated in a case study conducted on JHotDraw, an open source software system. The achieved results revealed that the performance achieved with the proposed approach significantly outperforms the results achieved with methods considering only structural or semantic information. The proposed approach has also been integrated in the Eclipse platform."
Sheneamer AM,An Automatic Advisor for Refactoring Software Clones Based on Machine Learning,2020,http://dx.doi.org/10.1109/ACCESS.2020.3006178,"To assist developers refactored code and to enable improvements to software quality when numbers of clones are found in software programs, we require an approach to advise developers on what a clone needs to refactor and what type of refactoring is needed. This paper suggests a unique learning method that automatically extracts features from the detected code clones and trains models to advise developers on what type needs to be refactored. Our approach differs from others, which specifies types of refactored clones as classes and creates a model for detecting the types of refactored clones and the clones which are anonymous. We introduce a new method by which to convert refactoring clone type outliers into Unknown to improve classification results. We present an extensive comparative study and an evaluation of the efficacy of our suggested idea by using state-of-the-art classification models"
"Bavota G,De Lucia A,Oliveto R",Identifying Extract Class refactoring opportunities using structural and semantic cohesion measures,2011,http://dx.doi.org/10.1016/j.jss.2010.11.918,"Approaches for improving class cohesion identify refactoring opportunities using metrics that capture structural relationships between the methods of a class, e.g., attribute references. Semantic metrics, e.g., C3 metric, have also been proposed to measure class cohesion, as they seem to complement structural metrics. However, until now semantic relationships between methods have not been used to identify refactoring opportunities. In this paper we propose an Extract Class refactoring method based on graph theory that exploits structural and semantic relationships between methods. The empirical evaluation of the proposed approach highlighted the benefits provided by the combination of semantic and structural measures and the potential usefulness of the proposed method as a feature for software development environments. (C) 2010 Elsevier Inc. All rights reserved."
"Bassey I,Dladlu N,Ele B",Object-Oriented Code Metric-Based Refactoring Opportunities Identification Approaches: analysis,2016,http://dx.doi.org/10.1109/ACIT-CSII-BCD.2016.24,"This paper presents analysis of existing empirical studies of software metric-based refactorings opportunities identification (ROI) for object-oriented (OO) software systems. We carried out a comprehensive analysis on sixteen (16) primary studies to identify the state-of-the-practice in ROI, focusing on their operations, refactoring activities, programming languages and the impact on software quality. The analysis results show that ROI approaches were designed for either a single refactoring activity or couple of them. Additionally, move method and extract class refactoring were the most refactorings activities performed on OO software systems. Also, OO metrics played an indispensable role in both opportunity detection and refactoring decisions. With the obtained results, we recommend the development of a generic ROI approach that is capable of identifying opportunities for all refactoring activities as well as suggesting the appropriate refactoring operations to apply."
"Shomrat M,Feldman YA",Detecting Refactored Clones,2013,,"The availability of automated refactoring tools in modern development environments allows programmers to refactor their code with ease. Such tools, however, enable developers to inadvertently create code clones that quickly diverge in form but not in meaning. Furthermore, in the hands of those looking to confuse plagiarism-detection tools, automated refactoring may be abused to avoid discovery of copied code. We present Cider, an algorithm that can detect code clones regardless of various refactorings that may have been applied to some of the copies but not to others. Most significant is the ability to discover interprocedural clones, where parts of one copy have been extracted to separate methods. We evaluated Cider on several open-source Java projects, attempting to detect interprocedural clones between successive versions of each project. Interprocedural clones were detected in all evaluated projects, demonstrating the pervasive nature of the problem. Compared to a manual assessment, Cider performed well in terms of both recall and precision."
"Counsell S,Swift S,Murgia A,Tonelli R,Marchesi M,Concas G",Are Some Refactorings Attached to Fault-Prone Classes and Others to Fault-Free Classes?,2014,,"A topical and relevant issue in the area of refactoring is the nature and characteristics of classes to which refactorings are applied. In particular, if we scrutinise the total set of refactorings applied to the classes of a system over different releases, which refactorings are applied to fault-prone classes and which to fault-free classes? In this paper, we explore that facet of refactoring. Refactorings applied between six releases of three Eclipse packages are used as a basis of the study and the Ref-Finder tool used to extract up to sixty-five different refactorings. Interestingly, results showed that refactorings applied to highly fault-prone classes differed significantly from those applied to fault-free classes, in particular related to the `rename method' refactoring; a corresponding trend for the `move method' and `move field' refactoring was found in `fault-free' classes over the period while the add and remove parameter refactorings tended to remain constant. The research offers an insight into refactoring behaviour in light of faults (or no faults)."
"Karakati CB,Thirumaaran S",Software code refactoring based on deep neural network-based fitness function,2023,http://dx.doi.org/10.1002/cpe.7531,"Refactoring is extensively recognized for enhancing the internal structure of object-oriented software while preserving its external behavior. However, determining refactoring opportunities is challenging for designers and researchers alike. In recent years, machine learning algorithms have shown a great possibility of resolving this issue. This study proposes a deep neural network-based fitness function (DNNFF) to resolve the software refactoring issue. This study suggests an effective learning technique that automatically featured extracted from the trained models and predicted code clones to recommend which category to refactor. The software engineers automatically assess the recommended refactoring solutions using Genetic Algorithms (GA) for minimum iterations. A Deep Neural Networks (DNN) utilizes these training instances to assess the refactoring solutions for the residual iterations. The refactoring process primarily depends on software designers' skills and perceptions. The simulation findings demonstrate that the suggested DNNFF model enhances the code change score of 98.7%, automatic refactoring score of 97.3%, defect correlation ratio of 96.9%, refactoring precision ratio of 95.9%, flaw detection ratio of 94.4%, and reduces the execution time of 10.2% compared to other existing methods."
"Hauptmann B,Eder S,Junker M,Juergens E,Woinke V",Generating Refactoring Proposals to Remove Clones from Automated System Tests,2015,http://dx.doi.org/10.1109/ICPC.2015.20,"Automated system tests often have many clones, which make them complex to understand and costly to maintain. Unfortunately, removing clones is challenging as there are numerous possibilities of how to refactor them to reuse components such as subroutines. Additionally, clones often overlap partly which makes it particularly difficult to decide which parts to extract. If done wrongly, reuse potential is not leveraged optimally and structures between tests and reuse components will become unnecessarily complex. We present a method to support test engineers in extracting overlapping clones. Using grammar inference algorithms, we generate a refactoring proposal that demonstrates test engineers how overlapping clones can be extracted. Furthermore, we visualize the generated refactoring proposal to make it easily understandable for test engineers. An industrial case study demonstrates that our approach helps test engineers to gain information of the reuse potential of test suites and guides them to perform refactorings."
"Saidani I,Ouni A,Mkaouer MW,Palomba F",On the impact of Continuous Integration on refactoring practice: An exploratory study on TravisTorrent,2021,http://dx.doi.org/10.1016/j.infsof.2021.106618,"Context: The ultimate goal of Continuous Integration (CI) is to support developers in integrating changes into production constantly and quickly through automated build process. While CI provides developers with prompt feedback on several quality dimensions after each change, such frequent and quick changes may in turn compromise software quality without Refactoring. Indeed, recent work emphasized the potential of CI in changing the way developers perceive and apply refactoring. However, we still lack empirical evidence to confirm or refute this assumption. Objective: We aim to explore and understand the evolution of refactoring practices, in terms of frequency, size and involved developers, after the switch to CI in order to emphasize the role of this process in changing the way Refactoring is applied. Method: We collect a corpus of 99,545 commits and 89,926 refactoring operations extracted from 39 opensource GitHub projects that adopt Travis CI and analyze the changes using Multiple Regression Analysis (MRA). Results: Our study delivers several important findings. We found that the adoption of CI is associated with a drop in the refactoring size as recommended, while refactoring frequency as well as the number (and its related rate) of developers that perform refactoring are estimated to decrease after the shift to CI, indicating that refactoring is less likely to be applied in CI context. Conclusion: Our study uncovers insights about CI theory and practice and adds evidence to existing knowledge about CI practices related especially to quality assurance. Software developers need more customized refactoring tool support in the context of CI to better maintain and evolve their software systems."
"Kebir S,Borne I,Meslati D",A genetic algorithm-based approach for automated refactoring of component-based software,2017,http://dx.doi.org/10.1016/j.infsof.2017.03.009,"Context: During its lifecycle, a software system undergoes repeated modifications to quickly fulfill new requirements, but its underlying design is not properly adjusted after each update. This leads to the emergence of bad smells. Refactoring provides a de facto behavior-preserving approach to eliminate these anomalies. However, manually determining and performing useful refactorings is a formidable challenge, as stated in the literature. Therefore, framing object-oriented automated refactoring as a search-based technique has been proposed. However, the literature shows that search-based refactoring of component based software has not yet received proper attention. Objective: This paper presents a genetic algorithm-based approach for the automated refactoring of component-based software. This approach consists of detecting component-relevant bad smells and eliminating these bad smells by searching for the best sequence of refactorings using a genetic algorithm. Method: Our approach consists of four steps. The first step includes studying the literature related to component-relevant bad smells and formulating bad smell detection rules. The second step involves proposing a catalog of component-relevant refactorings. The third step consists of constructing a source code model by extracting facts from the source code of a component-based software. The final step seeks to identify the best sequence of refactorings to apply to reduce the presence of bad smells in the source code model using a genetic algorithm. The latter uses bad smell detection rules as a fitness function and the catalog of refactorings as a means to explore the search space. Results: As a case study, we conducted experiments on an unbiased set of four real-world component based applications. The results indicate that our approach is able to efficiently reduce the total number of bad smells by more than one half, which is an acceptable value compared to the recent literature. Moreover, we determined that our approach is also accurate in refactoring only components suffering from bad smells while leaving the remaining components untouched whenever possible. Furthermore, a statistical analysis shows that our genetic algorithm outperforms random search and local search in terms of efficiency and accuracy on almost all the systems investigated in this work. Conclusion: This paper presents a search-based approach for the automated refactoring of component based software. To the best of our knowledge, our approach is the first to focus on component-based refactoring, whereas the state-of-the-art approaches focus only on object-oriented refactoring. (C) 2017 Elsevier B.V. All rights reserved."
"Panigrahi R,Kuanar SK,Misra S,Kumar L",Class-Level Refactoring Prediction by Ensemble Learning with Various Feature Selection Techniques,2022,http://dx.doi.org/10.3390/app122312217,"Background: Refactoring is changing a software system without affecting the software functionality. The current researchers aim i to identify the appropriate method(s) or class(s) that needs to be refactored in object-oriented software. Ensemble learning helps to reduce prediction errors by amalgamating different classifiers and their respective performances over the original feature data. Other motives are added in this paper regarding several ensemble learners, errors, sampling techniques, and feature selection techniques for refactoring prediction at the class level. Objective: This work aims to develop an ensemble-based refactoring prediction model with structural identification of source code metrics using different feature selection techniques and data sampling techniques to distribute the data uniformly. Our model finds the best classifier after achieving fewer errors during refactoring prediction at the class level. Methodology: At first, our proposed model extracts a total of 125 software metrics computed from object-oriented software systems processed for a robust multi-phased feature selection method encompassing Wilcoxon significant text, Pearson correlation test, and principal component analysis (PCA). The proposed multi-phased feature selection method retains the optimal features characterizing inheritance, size, coupling, cohesion, and complexity. After obtaining the optimal set of software metrics, a novel heterogeneous ensemble classifier is developed using techniques such as ANN-Gradient Descent, ANN-Levenberg Marquardt, ANN-GDX, ANN-Radial Basis Function; support vector machine with different kernel functions such as LSSVM-Linear, LSSVM-Polynomial, LSSVM-RBF, Decision Tree algorithm, Logistic Regression algorithm and extreme learning machine (ELM) model are used as the base classifier. In our paper, we have calculated four different errors i.e., Mean Absolute Error (MAE), Mean magnitude of Relative Error (MORE), Root Mean Square Error (RMSE), and Standard Error of Mean (SEM). Result: In our proposed model, the maximum voting ensemble (MVE) achieves better accuracy, recall, precision, and F-measure values (99.76, 99.93, 98.96, 98.44) as compared to the base trained ensemble (BTE) and it experiences less errors (MAE = 0.0057, MORE = 0.0701, RMSE = 0.0068, and SEM = 0.0107) during its implementation to develop the refactoring model. Conclusions: Our experimental result recommends that MVE with upsampling can be implemented to improve the performance of the refactoring prediction model at the class level. Furthermore, the performance of our model with different data sampling techniques and feature selection techniques has been shown in the form boxplot diagram of accuracy, F-measure, precision, recall, and area under the curve (AUC) parameters."
"Wang Y,Dong J,Shah R,Dillig I",Synthesizing Database Programs for Schema Refactoring,2019,http://dx.doi.org/10.1145/3314221.3314588,"Many programs that interact with a database need to undergo schema refactoring several times during their life cycle. Since this process typically requires making significant changes to the program's implementation, schema refactoring is often non-trivial and error-prone. Motivated by this problem, we propose a new technique for automatically synthesizing a new version of a database program given its original version and the source and target schemas. Our method does not require manual user guidance and ensures that the synthesized program is equivalent to the original one. Furthermore, our method is quite efficient and can synthesize new versions of database programs (containing up to 263 functions) that are extracted from real-world web applications with an average synthesis time of 69.4 seconds."
"Fernandes E,Uchoa A,Bibiano AC,Garcia A",On the Alternatives for Composing Batch Refactoring,2019,http://dx.doi.org/10.1109/IWoR.2019.00009,"Code refactoring is often performed for improving code structures through code transformations. Many transformations, e.g., extracting or moving a method, are applied for at least partially removing code smells. Each code smell is a symptom of a poor code structure that makes hard to read and change the program. Developers often compose two or more interrelated transformations in conjunction (batch refactoring) rather than applying a single transformation. For instance, developers often compose method extractions with method motions to better organize the features realized by classes. We have recently observed cases of batch refactoring performed along with code review in open source projects. We then noticed that composing batches capable of fully removing code smells is quite challenging. Especially, it requires carefully discussing on how two or more transformations complement one another and what to expect from the batch effect on code smell. This position aims to reason about multiple alternatives to support developers on composing their batches. These alternatives should make it easier to compose batches that remove code smells. For this purpose, we exemplify the role of semi-automated tools in gradually recommending transformations, thereby guiding the batch composition in each alternative."
"Tsantalis N,Chatzigeorgiou A",Identification of Move Method Refactoring Opportunities,2009,http://dx.doi.org/10.1109/TSE.2009.1,"Placement of attributes/methods within classes in an object-oriented system is usually guided by conceptual criteria and aided by appropriate metrics. Moving state and behavior between classes can help reduce coupling and increase cohesion, but it is nontrivial to identify where such refactorings should be applied. In this paper, we propose a methodology for the identification of Move Method refactoring opportunities that constitute a way for solving many common Feature Envy bad smells. An algorithm that employs the notion of distance between system entities (attributes/methods) and classes extracts a list of behavior-preserving refactorings based on the examination of a set of preconditions. In practice, a software system may exhibit such problems in many different places. Therefore, our approach measures the effect of all refactoring suggestions based on a novel Entity Placement metric that quantifies how well entities have been placed in system classes. The proposed methodology can be regarded as a semi-automatic approach since the designer will eventually decide whether a suggested refactoring should be applied or not based on conceptual or other design quality criteria. The evaluation of the proposed approach has been performed considering qualitative, metric, conceptual, and efficiency aspects of the suggested refactorings in a number of open-source projects."
"Hora A,Etien A,Anquetil N,Ducasse S,Valente MT",APIEvolutionMiner: Keeping API Evolution under Control,2014,,"During software evolution, source code is constantly refactored. In real-world migrations, many methods in the newer version are not present in the old version (e.g., 60% of the methods in Eclipse 2.0 were not in version 1.0). This requires changes to be consistently applied to reflect the new API and avoid further maintenance problems. In this paper, we propose a tool to extract rules by monitoring API changes applied in source code during system evolution. In this process, changes are mined at revision level in code history. Our tool focuses on mining invocation changes to keep track of how they are evolving. We also provide three case studies in order to evaluate the tool."
"Zhang Y,Ge C,Hong S,Tian R,Dong C,Liu J",DeleSmell: Code smell detection based on deep learning and latent semantic analysis,2022,http://dx.doi.org/10.1016/j.knosys.2022.109737,"The presence of code smells will increase the risk of failure, make software difficult to maintain, and introduce potential technique debt in the future. Although many deep-learning-based approaches have been proposed to detect code smells, most existing works suffer from the problem of incomplete feature extraction and unbalanced distribution between positive samples and negative samples. Furthermore, the accuracy of existing works can be further improved. This paper proposes a novel approach named DeleSmell to detect code smells based on a deep learning model. The dataset is built by extracting samples from 24 real-world projects. To improve the imbalance in the dataset, a refactoring tool is developed to automatically transform good source code into smelly code and to generate positive samples based on real cases. DeleSmell collects both structural features through iPlasma and semantic features via latent semantic analysis and word2vec. DeleSmell's model includes a convolutional neural network(CNN) branch and gate recurrent unit(GRU)-attention branch. The final classification is conducted by an support vector machine(SVM). In the experimentation, the effectiveness of DeleSmell is evaluated by answering seven research questions. The experimental results show that DeleSmell improves the accuracy of brain class (BC) and brain method (BM) code smells detection by up to 4.41% compared with existing approaches, demonstrating the effectiveness of our approach. (c) 2022 Elsevier B.V. All rights reserved."
"Akash PS,Sadiq AZ,Kabir A",An Approach of Extracting God Class Exploiting Both Structural and Semantic Similarity,2019,http://dx.doi.org/10.5220/0007743804270433,"Code smell is a sign of design and development flaws in a software system which reduces the reusability and maintainability of the system. Refactoring is a continuous practice of eliminating code smells from the source code. A God Class is one of the most common code smells where too many responsibilities are defined in a single class. God Classes reduce the quality of a system by increasing coupling and decreasing cohesion. In this paper, we propose an approach for extracting a God Class into new classes by increasing class cohesion. For this, both structural and semantic relationship between methods in a class are analyzed, and strongly related methods are clustered and suggested to be in the same class. We assessed the proposed approach on fifteen real God Classes from two well-known open source systems and it is shown that the cohesion among the classes is increased after refactoring. A comparative result of our approach with a similar existing approach is presented and it is found that our approach provides better results for almost all the experimented God Classes."
"Beillahi SM,Bouajjani A,Enea C,Lahiri S",Automated Synthesis of Asynchronizations,2022,http://dx.doi.org/10.1007/978-3-031-22308-2_7,"Asynchronous programming is widely adopted for building responsive and efficient software, and modern languages such as C# provide async/await primitives to simplify the use of asynchrony. In this paper, we propose an approach for refactoring a sequential program into an asynchronous program that uses async/await, called asynchronization. The refactoring process is parametrized by a set of methods to replace with asynchronous versions, and it is constrained to avoid introducing data races. We investigate the delay complexity of enumerating all data race free asynchronizations, which quantifies the delay between outputting two consecutive solutions. We show that this is polynomial time modulo an oracle for solving reachability in sequential programs. We also describe a pragmatic approach based on an interprocedural data-flow analysis with polynomial-time delay complexity. The latter approach has been implemented and evaluated on a number of non-trivial C# programs extracted from open-source repositories."
"Palomba F,Panichella A,Zaidman A,Oliveto R,De Lucia A",The Scent of a Smell: An Extensive Comparison Between Textual and Structural Smells,2018,http://dx.doi.org/10.1109/TSE.2017.2752171,"Code smells are symptoms of poor design or implementation choices that have a negative effect on several aspects of software maintenance and evolution, such as program comprehension or change- and fault-proneness. This is why researchers have spent a lot of effort on devising methods that help developers to automatically detect them in source code. Almost all the techniques presented in literature are based on the analysis of structural properties extracted from source code, although alternative sources of information (e.g., textual analysis) for code smell detection have also been recently investigated. Nevertheless, some studies have indicated that code smells detected by existing tools based on the analysis of structural properties are generally ignored (and thus not refactored) by the developers. In this paper, we aim at understanding whether code smells detected using textual analysis are perceived and refactored by developers in the same or different way than code smells detected through structural analysis. To this aim, we set up two different experiments. We have first carried out a software repository mining study to analyze how developers act on textually or structurally detected code smells. Subsequently, we have conducted a user study with industrial developers and quality experts in order to qualitatively analyze how they perceive code smells identified using the two different sources of information. Results indicate that textually detected code smells are easier to identify and for this reason they are considered easier to refactor with respect to code smells detected using structural properties. On the other hand, the latter are often perceived as more severe, but more difficult to exactly identify and remove."
"Bavota G,De Lucia A,Marcus A,Oliveto R",Automating extract class refactoring: an improved method and its evaluation,2014,http://dx.doi.org/10.1007/s10664-013-9256-x,"During software evolution the internal structure of the system undergoes continuous modifications. These continuous changes push away the source code from its original design, often reducing its quality, including class cohesion. In this paper we propose a method for automating the Extract Class refactoring. The proposed approach analyzes (structural and semantic) relationships between the methods in a class to identify chains of strongly related methods. The identified method chains are used to define new classes with higher cohesion than the original class, while preserving the overall coupling between the new classes and the classes interacting with the original class. The proposed approach has been first assessed in an artificial scenario in order to calibrate the parameters of the approach. The data was also used to compare the new approach with previous work. Then it has been empirically evaluated on real Blobs from existing open source systems in order to assess how good and useful the proposed refactoring solutions are considered by software engineers and how well the proposed refactorings approximate refactorings done by the original developers. We found that the new approach outperforms a previously proposed approach and that developers find the proposed solutions useful in guiding refactorings."
"Saheb-Nassagh R,Ashtiani M,Minaei-Bidgoli B",A probabilistic-based approach for automatic identification and refactoring of software code smells,2022,http://dx.doi.org/10.1016/j.asoc.2022.109658,"Programmers strive to design programs that are flexible, updateable, and maintainable. However, several factors such as lack of time, high costs, and workload lead to the creation of software with inadequacies known as anti-patterns. To identify and refactor software anti-patterns, many research studies have been conducted using machine learning. Even though some of the previous works were very accurate in identifying anti-patterns, a method that takes into account the relationships between different structures is still needed. Furthermore, a practical method is needed that is trained according to the characteristics of each program. This method should be able to identify anti-patterns and perform the necessary refactorings. This paper proposes a framework based on probabilistic graphical models for identifying and refactoring anti-patterns. A graphical model is created by extracting the class properties from the source code. As a final step, a Bayesian network is trained, which determines whether anti-patterns are present or not based on the characteristics of neighboring classes. To evaluate the proposed approach, the model is trained on six different anti-patterns and six different Java programs. The proposed model has identified these anti-patterns with a mean accuracy of 85.16 percent and a mean recall of 79%. Additionally, this model has been used to introduce several methods for refactoring, and it has been shown that these refactoring methods will ultimately create a system with less coupling and higher cohesion."
"Gupta R,Singh SK",Using Software Metrics to detect Temporary Field code smell,2020,,"Code smell is a characteristic of the source code which indicates so me serious problem in the code which might affect the quality of the source code. There exists a list of 22 code smells as defined by Martin Fowler. But all these code smells have not been worked upon. Temporary field code smell is one of them, which has not been considered for its detection and refactoring. In this paper, we have reconstructed a motivating example of object oriented JAVA code that indicates the impact of code smell and need to remove temporary field based on metrics and rules. We have proposed a method to detect temporary field code smell based on software metrics derived from data flow and control flow graphs. We also proposed the process of refactoring the code to improve the maintainability. Analysis of results has shown that NFM, NMN, NCF metrics can help to detect Temporary field code smell. Extract class is more appropriate refactoring technique than parameter passing to remove Temporary Field code smell."
"Machado L,Cortadella J",Boolean Decomposition for AIG Optimization,2017,http://dx.doi.org/10.1145/3060403.3060420,"Restructuring techniques for And-Inverter Graphs (AIG), such as rewriting and refactoring, are powerful, scalable and fast, achieving highly optimized AIGs after few iterations. However, these techniques are biased by the original AIG structure and limited by single output optimizations. This paper investigates AIG optimization for area, exploring how far Boolean methods can reduce AIG nodes through local optimization. Boolean division is applied for multi-output functions using two-literal divisors and Boolean decomposition is introduced as a method for AIG optimization. Multi output blocks are extracted from the AIG and optimized, achieving a further AIG node reduction of 7.76% on average for ITC99 and MCNC benchmarks."
"Bisztray D,Heckel R,Ehrig H",Verification of architectural refactorings by rule extraction,2008,,"With the success of model-driven development as well as component-based and service-oriented systems, models of software architecture are key artefacts in the development process. To adapt to changing requirements and improve internal software quality such models have to evolve while preserving aspects of their behaviour. To avoid the costly verification of refactoring steps on large systems we present a method which allows us to extract a (usually much smaller) rule from the transformation performed and verify this rule instead. The main result of the paper shows that the verification of rules is indeed sufficient to guarantee the desired semantic relation between source and target models. We apply the approach to the refactoring of architectural models based on UML component, structure, and activity diagrams, with using CSP as a semantic domain."
Udagawa Y,An Empirical Study on Retrieving Structural Clones Using Sequence Pattern Mining Algorithms,2014,,"Many clone detection techniques focus on fragments of duplicated code, i.e., simple clones. Structural clones are simple clones within a syntactic boundary that are good candidates for refactoring. In this paper, a new approach for detection of structural clones in source code is presented. The proposed approach is parse-tree-based and is enhanced by frequent subsequence mining. It comprises three stages: preprocessing, mining frequent statement sequences, and fine-matching for structural clones using a modified longest common subsequence (LCS) algorithm. The lengths of control statements in a programming language and method identifiers differ; thus, a conventional LCS algorithm does not return the expected length of matched identifiers. We propose an encoding algorithm for control statements and method identifiers. Retrieval experiments were conducted using the Java SWING source code. The results show that the proposed data mining algorithm detects clones comprising 51 extracted statements. Our modified LCS algorithm retrieves a number of structural clones with arbitrary statement gaps."
"Pappalardo G,Tramontana E",Suggesting Extract Class Refactoring Opportunities by Measuring Strength of Method Interactions,2013,http://dx.doi.org/10.1109/APSEC.2013.123,"For improving the modularity of a large software system, metrics can be valuable to help finding refactoring opportunities for classes. We define a novel metric that is intended to suggest how closely connected are the elements of a class. The metric characterises the strength of the coupling between methods of a class, based on invocations and the size of the parameters involved, as well as attribute accesses. The assessment of the strength of interactions turns out to be valuable in providing an indication on the possible changes that classes need to become more modular and prone to be reused. According to the computed metric and the assessment of system-wide relationships between classes, we are able to suggest Extract Class refactoring opportunities. The capability of the proposed approach to evaluate object-oriented systems is demonstrated by analysing a large software system."
"Abadi A,Ettinger R,Feldman YA",Fine Slicing Theory and Applications for Computation Extraction,2012,,"Software evolution often requires the untangling of code. Particularly challenging and error-prone is the task of separating computations that are intertwined in a loop. The lack of automatic tools for such transformations complicates maintenance and hinders reuse. We present a theory and implementation of fine slicing, a method for computing executable program slices that can be finely tuned, and can be used to extract non-contiguous pieces of code and untangle loops. Unlike previous solutions, it supports temporal abstraction of series of values computed in a loop in the form of newly-created sequences. Fine slicing has proved useful in capturing meaningful subprograms and has enabled the creation of an advanced computation-extraction algorithm and its implementation in a prototype refactoring tool for Cobol and Java."
"dos Reis JP,Brito e Abreu F,Carneiro GF,Anslow C",Code Smells Detection and Visualization: A Systematic Literature Review,2022,http://dx.doi.org/10.1007/s11831-021-09566-x,"Code smells tend to compromise software quality and also demand more effort by developers to maintain and evolve the application throughout its life-cycle. They have long been catalogued with corresponding mitigating solutions called refactoring operations. Researchers have argued that due to the subjectiveness of the code smells detection process, proposing an effective use of automatic support for this end is a non trivial task. This systematic literature review (SLR) has a twofold goal: the first is to identify the main code smells detection techniques and tools discussed in the literature, and the second is to analyze to which extent visual techniques have been applied to support the former. Over eighty primary studies indexed in major scientific repositories were identified by our search string in this SLR. Then, following existing best practices for secondary studies, we applied inclusion/exclusion criteria to select the most relevant works, extract their features and classify them. We found that the most commonly used approaches to code smells detection are search-based (30.1%), metric-based (24.1%), and symptom-based approaches (19.3%). Most of the studies (83.1%) use open-source software, with the Java language occupying the first position (77.1%). In terms of code smells, God Class (51.8%), Feature Envy (33.7%), and Long Method (26.5%) are the most covered ones. Machine learning (ML) techniques are used in 35% of the studies, with genetic programming, decision tree, support vector machines and association rules being the most used algorithms. Around 80% of the studies only detect code smells, without providing visualization techniques. In visualization-based approaches several methods are used, such as: city metaphors, 3D visualization techniques, interactive ambient visualization, polymetric views, or graph models. This paper presents an up-to-date review on the state-of-the-art techniques and tools used for code smells detection and visualization. We confirm that the detection of code smells is a non trivial task, and there is still a lot of work to be done in terms of: reducing the subjectivity associated with the definition and detection of code smells; increasing the diversity of detected code smells and of supported programming languages; constructing and sharing oracles and datasets to facilitate the replication of code smells detection and visualization techniques validation experiments."
"Mirson A,Skrypnyuk O,Elezi F,Lindemann U",MDM-BASED SOFTWARE MODULARIZATION BY ANALYSING INTER-PROJECT DEPENDENCIES,2011,,In this paper we explore the possibilities of improving software architecture by eliminating inter-project dependencies and extracting subprojects into plugins. A new approach is proposed to improve the modularization process and to support software architects to reach better decisions on how to reorganize the software system and to get loosely connected architecture in a way that the subprojects of the system are extracted into standalone plug-ins. This method is using the MDM model and has been implemented in software called LOOMEO as a standalone plugin to illustrate its applicability. As a case study we used the software LOOMEO itself to proof our concept. This method provides a solid framework for improving the refactoring process in multi-project environment.
"Ben Asher Y,Gal T,Haber G,Zalmanovici M",Refactoring techniques for aggressive object inlining in Java applications,2012,http://dx.doi.org/10.1007/s10515-011-0096-x,"Object Inlining (OI) is a known optimization in object oriented programming in which referenced objects of class B are inlined into their referencing objects of class A by making all fields and methods of class B part of class A. The optimization saves all the new operations of B type objects from class A and at the same time replaces all indirect accesses, from A to fields of B, by direct accesses. To the best of our knowledge, in-spite of the significant performance potential of the OI optimization, reported performance measurements were relatively moderate. This is because an aggressive OI optimization requires complex analysis and code transformations to overcome problems like multiple references to the inlinable object, object references that escape their object scope, etc. To extract the full potential of OI, we propose a two-stage process. The first stage includes automatic analysis of the source code that informs the user, via comments in the IDE, about code transformations that are needed in order to enable or to maximize the potential of the OI optimization. In the second stage, the OI optimization is applied automatically on the source code as a code refactoring operation, or preferably, as part of the compilation process prior to javac run. We show that this half-automated technique helps to extract the full potential of OI. The proposed OI refactoring process also determines the order of applying the inlinings of the objects and enables us to apply inlinings of objects created inside a method; thus enabling us to reach better performance gain. In this work we also include an evaluation of the OI optimization effects on multithreaded applications running on multicore machines. The comments and the OI transformation were implemented in the Eclipse JDT (Java Development Tools) plugin. The system was then applied on the SPECjbb2000 source code along with profiling data collected by the Eclipse TPTP plugin. The proposed system achieved 46% improvement in performance."
"Meng C,Xiao-hong S,Tian-tian W,Pei-jun M",A New Clone Group Mapping Algorithm for Extracting Clone Genealogy on Multi-Version Software,2013,http://dx.doi.org/10.1109/IMCCC.2013.189,"Research on code clone evolution is very hot, and it can contribute to the investigation of the characteristics, the maintenance, the refactoring, and the harmfulness evaluation of code clones. In clone evolution research, extracting clone genealogies is the key technique, and mapping clone groups between neighboring software versions is a thorny issue for extracting clone genealogies. The efficiency and robustness of the current method are not satisfactory. To address this problem, this paper presents a new clone group mapping algorithm in order to extract the clone genealogy. The algorithm takes NICAD's results as input, and describes the information of code clones with CRD, and maps the clone groups as well as the clone fragments according to the CRD matching level, the location overlapping rate and if necessary the text similarity rate. We evaluate our method on three software systems of different size and written in different languages. The results show that our method works well in clone group mapping under various circumstances, and it also can as a reliable foundation for constructing clone genealogies."
"Cabral JB,Sanchez B,Ramos F,Gurovich S,Granitto PM,Vanderplas J",From FATS to feets: Further improvements to an astronomical feature extraction tool based on machine learning,2018,http://dx.doi.org/10.1016/j.ascom.2018.09.005,"Machine learning algorithms are highly useful for the classification of time series data in astronomy in this era of peta-scale public survey data releases. These methods can facilitate the discovery of new unknown events in most astrophysical areas, as well as improving the analysis of samples of known phenomena. Machine learning algorithms use features extracted from collected data as input predictive variables. A public tool called Feature Analysis for Time Series (FATS) has proved an excellent workhorse for feature extraction, particularly light curve classification for variable objects. In this study, we present a major improvement to FATS, which corrects inconvenient design choices, minor details, and documentation for the re-engineering process. This improvement comprises a new Python package called feets, which is important for future code-refactoring for astronomical software tools. (C) 2018 Elsevier B.V. All rights reserved."
Szwed P,Enhancing Concept Extraction from Polish Texts with Rule Management,2016,http://dx.doi.org/10.1007/978-3-319-34099-9_27,"This paper presents a system for extraction of concepts from unstructured Polish texts. Here concepts are understood as n-grams, whose words satisfy specific grammatical constraints. Detection and transformation of concepts to their normalized form are performed with rules defined in a language, which combines elements of colored and fuzzy Petri nets. We apply a user friendly method for specification of samples of transformation patterns that are further compiled to rules. To improve accuracy and performance, we recently introduced rule management mechanisms, which are based on two relations between rules: partial refinement and covering. The implemented methods include filtering with metarules and removal of redundant rules (i.e. these covered by other rules). We report results of experiments, which aimed at extracting specific concepts (actions) using a ruleset refactored with the developed rule management techniques."
"Zhou K,Zhang X,Yan X",A New Approach of Spectrum Compression based on Morphology Filter,2017,,"Aiming at solving the problem of transmitting and storing radio spectrum data in large volume, this paper proposes a new method in data compression and refactoring. Based on the research of mathematical morphology, the method designs a morphology filter by which spectrum form could be determined by extraction of its features according to structural element. Advantage of this method lies in significantly increasing the compressing ratio while maintaining good performance in signal-noise separation and signal feature reservation, realized by extracting signal and noise respectively, and using appropriate structural element to match the form of noise. Being tested in experiment, this method has been proved to be effective in compressing radio spectrum data, which provides a new approach in its transmission and storage preprocessing."
"Walter B,Fontana FA,Ferme V",Code smells and their collocations: A large-scale experiment on open-source systems,2018,http://dx.doi.org/10.1016/j.jss.2018.05.057,"Code smells indicate possible flaws in software design, that could negatively affect system's maintainability. Interactions among smells located in the same classes (i.e., collocated smells) have even more detrimental effect on quality. Extracted frequent patterns of collocated smells could help to understand practical consequences of collocations. In this paper we identify and empirically validate frequent collocations of 14 code smells detected in 92 Java systems, using three approaches: pairwise correlation analysis, PCA and associative rules. To cross validate the results, we used up to 6 detectors for each smell. Additionally, we examine and compare techniques used to extract the relationships. The contribution is three-fold: (1) we identify and empirically validate relationships among the examined code smells on a large dataset that we made publicly available, (2) we discuss how the choice of code smell detectors affects results, and (3) we analyze the impact of software domain on existence of the smell collocations. Additionally, we found that analytical methods we used to discover collocations, are complementary. Smells collocations display recurring patterns that could help prioritizing the classes affected by code smells to be refactored and developing or enhancing detectors exploiting information about collocations. They can also help the developers focusing on classes deserving more maintenance effort."
"Pourasghar B,Izadkhah H,Isazadeh A,Lotfi S",A graph-based clustering algorithm for software systems modularization,2021,http://dx.doi.org/10.1016/j.infsof.2020.106469,"Context: Clustering algorithms, as a modularization technique, are used to modularize a program aiming to understand large software systems as well as software refactoring. These algorithms partition the source code of the software system into smaller and easy-to-manage modules (clusters). The resulting decomposition is called the software system structure (or software architecture). Due to the NP-hardness of the modularization problem, evolutionary clustering approaches such as the genetic algorithm have been used to solve this problem. These methods do not make much use of the information and knowledge available in the artifact dependency graph which is extracted from the source code. Objective: To overcome the limitations of the existing modularization techniques, this paper presents a new modularization technique named GMA (Graph-based Modularization Algorithm). Methods: In this paper, a new graph-based clustering algorithm is presented for software modularization. To this end, the depth of relationships is used to compute the similarity between artifacts, as well as seven new criteria are proposed to evaluate the quality of a modularization. The similarity presented in this paper enables the algorithm to use graph-theoretic information. Results: To demonstrate the applicability of the proposed algorithm, ten folders of Mozilla Firefox with different domains and functions, along with four other applications, are selected. The experimental results demonstrate that the proposed algorithm produces modularization closer to the human expert's decomposition (i.e., directory structure) than the other existing algorithms. Conclusion: The proposed algorithm is expected to help a software designer in the software reverse engineering process to extract easy-to-manage and understandable modules from source code."
"Ferber M,Hunold S,Krellner B,Rauber T,Reichel T,Ruenger G",Reducing the Class Coupling of Legacy Code by a Metrics-Based Relocation of Class Members,2012,,"With the rapid growth of the complexity of software systems. the problem of integrating and maintaining legacy software is more relevant than ever. To overcome this problem, many methods for refactoring legacy code have already been proposed such as renaming classes or extracting interfaces. To perform a real modularization. methods have to be moved between classes. However. moving a single method is often not possible due to code dependencies. In this article we present an approach to modularize legacy software by moving multiple related class members. It is shown how to identify groups of class members with similar concerns. We present two different code patterns that the related members and their dependent classes must match to allow a relocation of the related members. We also demonstrate how our pattern-based approach for automated modularization of legacy software can be applied to two open source projects."
"Hadj-Kacem M,Bouassida N",A Hybrid Approach To Detect Code Smells using Deep Learning,2018,http://dx.doi.org/10.5220/0006709801370146,"The detection of code smells is a fundamental prerequisite for guiding the subsequent steps in the refactoring process. The more the detection results are accurate, the more the performance of the refactoring on the software is improved. Given its influential role in the software maintenance, this challenging research topic has so far attracted an increasing interest. However, the lack of consensus about the definition of code smells in the literature has led to a considerable diversity of the existing results. To reduce the confusion associated with this lack of consensus, there is a real need to achieve a deep and consistent representation of the code smells. Recently, the advance of deep learning has demonstrated an undeniable contribution in many research fields including the pattern recognition issues. In this paper, we propose a hybrid detection approach based on deep Auto-encoder and Artificial Neural Network algorithms. Four code smells (God Class, Data Class, Feature Envy and Long Method) are the focus of our experiment on four adopted datasets that are extracted from 74 open source systems. The values of recall and precision measurements have demonstrated high accuracy results."
"Athanasopoulos D,Zarras AV,Miskos G,Issarny V,Vassiliadis P",Cohesion-Driven Decomposition of Service Interfaces without Access to Source Code,2015,http://dx.doi.org/10.1109/TSC.2014.2310195,"Software cohesion concerns the degree to which the elements of a module belong together. Cohesive software is easier to understand, test and maintain. In the context of service-oriented development, cohesion refers to the degree to which the operations of a service interface belong together. In the state of the art, software cohesion is improved based on refactoring methods that rely on information, extracted from the software implementation. This is a main limitation towards using these methods in the case of web services: web services do not expose their implementation; instead all that they export is the web service interface specification. To deal with this problem, we propose an approach that enables the cohesion-driven decomposition of service interfaces, without information on how the services are implemented. Our approach progressively decomposes a given service interface into more cohesive interfaces; the backbone of the approach is a suite of cohesion metrics that rely on information, extracted solely from the specification of the service interface. We validate the approach in 22 real-world services, provided by Amazon and Yahoo. We assess the effectiveness of the proposed approach, concerning the cohesion improvement, and the number of interfaces that result from the decomposition of the examined interfaces. Moreover, we show the usefulness of the approach in a user study, where developers assessed the quality of the produced interfaces."
"Alrabaee S,Shirani P,Wang L,Debbabi M,Hanna A",On Leveraging Coding Habits for Effective Binary Authorship Attribution,2018,http://dx.doi.org/10.1007/978-3-319-99073-6_2,"We propose BinAuthor, a novel and the first compiler-agnostic method for identifying the authors of program binaries. Having filtered out unrelated functions (compiler and library) to detect user-related functions, it converts user-related functions into a canonical form to eliminate compiler/compilation effects. Then, it leverages a set of features based on collections of author's choices made during coding. These features capture an author's coding habits. Our evaluation demonstrated that Binkuthor outperforms existing methods in several respects. First, when tested on large datasets extracted from selected open-source C/C++ projects in GitHub, Google Code Jam events, and Planet Source Code contests, it successfully attributed a larger number of authors with a significantly higher accuracy: around 90% when the number of authors is 1000. Second, when the code was subjected to refactoring techniques, code transformation, or processing using different compilers or compilation settings, there was no significant drop in accuracy, indicating that Binkuthor is more robust than previous methods."
"Wang H,Liu J,Kang J,Yin W,Sun H,Wang H",Feature Envy Detection based on Bi-LSTM with Self-Attention Mechanism,2020,http://dx.doi.org/10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00082,"Code Smell refers to suboptimal or harmful structures in the source code that may impede the maintainability of software. It serves as an effective way to detect refactoring opportunities. As the most prevailing smell, Feature Envy and its detection has been deeply explored for many years, which produces massive automated detection methods. Nevertheless, the heuristic-based approach cannot reach a satisfying level, and the machine learning approach still needs further optimization. Recent advances in deep learning inspire the birth of deep learning based approach. In this paper, we define a simpler distance metric as numerical feature and we collect class name and method name as text feature. Then we leverage Bidirectional Long-Short Term Memory (Bi-LSTM) Network with self-attention mechanism to extract semantic distance information in the text part, and we adopt embedding technology to enhance the structure distance information in the numerical part. Combined with the two sophisticatedly designed modules and the final classification module, a more reliable and accurate model is presented. Experimental results on seven open-source Java projects show that our model significantly outperforms existing methods."
"Hu S,Li Q,Chen P,Chu H,Su Y,Wang Y",Finding aspects in Object-Oriented system,2006,,"In large Object-Oriented systems, complex relationships among classes are difficult for developers to comprehend, maintain, refactor and migrate. To overcome the obstacle, the classes are separated into different aspects. Source code has been analyzed and all static and dynamic information is extracted. Based on the information collected, TDG (Type Dependency Graph) is constructed and a hierarchy of aspects has been mined from TDG through an aspect mining method. Each class of the system is put into one aspect. The aspect in the lower level of hierarchy is the foundation of the higher one. The hierarchy gives out the roadmap to comprehend the system and developers find it easy to follow. A Reverse Engineering Tool XDRE (XiDian Reverse Engineering) has been developed to find aspects. (connector)A large Client-Server Object-Oriented System has been analyzed by XDRE, and the results show its effectiveness."
"Alrabaee S,Shirani P,Wang L,Debbabi M",FOSSIL: A Resilient and Efficient System for Identifying FOSS Functions in Malware Binaries,2018,http://dx.doi.org/10.1145/3175492,"Identifying free open-source software (FOSS) packages on binaries when the source code is unavailable is important for many security applications, such as malware detection, software infringement, and digital forensics. This capability enhances both the accuracy and the efficiency of reverse engineering tasks by avoiding false correlations between irrelevant code bases. Although the FOSS package identification problem belongs to the field of software engineering, conventional approaches rely strongly on practical methods in data mining and database searching. However, various challenges in the use of these methods prevent existing function identification approaches from being effective in the absence of source code. To make matters worse, the introduction of obfuscation techniques, the use of different compilers and compilation settings, and software refactoring techniques has made the automated detection of FOSS packages increasingly difficult. With very few exceptions, the existing systems are not resilient to such techniques, and the exceptions are not sufficiently efficient. To address this issue, we propose FOSSIL, a novel resilient and efficient system that incorporates three components. The first component extracts the syntactical features of functions by considering opcode frequencies and applying a hidden Markov model statistical test. The second component applies a neighborhood hash graph kernel to random walks derived from control-flow graphs, with the goal of extracting the semantics of the functions. The third component applies z-score to the normalized instructions to extract the behavior of instructions in a function. The components are integrated using a Bayesian network model, which synthesizes the results to determine the FOSS function. The novel approach of combining these components using the Bayesian network has produced stronger resilience to code obfuscation. We evaluate our system on three datasets, including real-world projects whose use of FOSS packages is known, malware binaries for which there are security and reverse engineering reports purporting to describe their use of FOSS, and a large repository of malware binaries. We demonstrate that our system is able to identify FOSS packages in real-world projects with a mean precision of 0.95 and with a mean recall of 0.85. Furthermore, FOSSIL is able to discover FOSS packages in malware binaries that match those listed in security and reverse engineering reports. Our results show that modern malware binaries contain 0.10-0.45 of FOSS packages."
"Singh S,Werle D,Koziolek A",ARCHI4MOM: Using Tracing Information to Extract the Architecture of Microservice-Based Systems from Message-Oriented Middleware,2022,http://dx.doi.org/10.1007/978-3-031-16697-6_14,"Microservice architectures that use Message-oriented Middleware (MOM) have recently seen considerable evolution regarding extensibility, re-usability and maintainability. Of particular interest are systems that are distributed and deployed with mixed-technologies. On the one hand, such MOM-based microservice systems improve flexibility through their messaging middleware. On the other hand, configuration for the above systems has to quickly adapt to required changes because of the continuous development process. Architecture reconstruction methods from dynamic data can keep architecture documentation and models in synchrony with the implemented architecture for such systems. However, the existing dynamic analysis methods for architecture reconstruction do not support the extraction for MOM-based microservice systems. The main challenge here is to understand and capture the asynchronous senderreceiver communication via the messaging middleware and to reconstruct the architecture model from it. In our work, we provide the ARCHI4MOM approach to automate the architecture extraction process. We instrument the sender-receiver and messaging services, collect run time data, analyse the trace data and construct the model from it. Architects can use the extracted architecture model for system refactoring and analysis of MOMbased systems. Thus, it reduces the cost and time required for manual architecture extraction process. We evaluate the accuracy of the approach by comparing the extracted model components to a manually crafted baseline model for a case study system."
"Abrantes JF,Travassos GH",Common Agile Practices in Software Processes,2011,http://dx.doi.org/10.1109/ESEM.2011.47,"Objective: to investigate studies about software processes looking for practices which can be used to obtain agility in software processes. Method: A systematic review including seven search engines was executed in Feb/2010. To apply the defined criteria to select papers and extract information regarding working practices bringing agility to software processes. Results: from 6696 retrieved papers, 441 were selected to support the identification of 236 occurrences of 51 distinct practices associated with the concept of agility. Their descriptions were deeply analyzed and consolidated. After discarding those which appeared in the technical literature in a small amount of papers, 17 agile practices were identified. Conclusion: although further studies are necessary to evaluate the efficacy of these 17 agile practices, 12 of them have been more commonly approached in the software projects and could be primarily considered: test driven development, continuous integration, pair programming, planning game, on-site customer, collective code ownership, small releases, metaphor, refactoring, sustainable pace, simple design and coding standards."
"Kim T,Kim S,Ryu D",Coding (TM): Development Task Visualization for SW Code Comprehension,2021,http://dx.doi.org/10.1109/VISSOFT52517.2021.00012,"In a software development project, a developer tends to use the `diff' view of the version control system (VCS) to understand development tasks such as fixing bugs, adding new features, and refactoring. However, the view only shows the difference of resources between the recent and previous versions in a commit, without providing any information about associated updates for completing a specific task. This causes a developer to spend a lot of time understanding development tasks, especially in the project where source code should be shared throughout team members. In order to handle this issue, we propose a novel tool Coding Time-Machine, in short Coding (TM), that automatically identifies and visualizes development tasks and their associated task elements (e.g., class and method). Coding (TM) extracts development tasks composed of task elements and causal relationships between them in a commit and facilitates one to compare the recent version of a code to the previous for each task. In addition, it allows one to navigate tasks of all commits in the code repository so that a developer feels like carrying out the time-travel of the coding activities in the software development project. For the evaluation, we measured the performance of tasks extracted from Coding (TM) for eight open-source Java projects, and obtained 0.87 of precision and 0.88 of recall. Also, we surveyed the usefulness of our tool for 20 participants, 80% of participants thought that showing tasks and their associated elements in a commit helps one to comprehend source code, and all participants responded that showing tasks in a chronicle way facilitates one to understand coding activities."
"Wang S,Bansal C,Nagappan N",Large-scale intent analysis for identifying large-review-effort code changes,2021,http://dx.doi.org/10.1016/j.infsof.2020.106408,"Context: Code changes to software occur due to various reasons such as bug fixing, new feature addition, and code refactoring. Change intents have been studied for years to help developers understand the rationale behind code commits. However, in most existing studies, the intent of the change is rarely leveraged to provide more specific, context aware analysis. Objective: In this paper, we present the first study to leverage change intent to characterize and identify Large-Review-Effort (LRE) changes-changes with large review effort. Method: Specifically, we first propose a feedback-driven and heuristics-based approach to identify change intents of code changes. We then characterize the changes regarding review effort by using various features extracted from change metadata and the change intents. We further explore the feasibility of automatically classifying LRE changes. We conduct our study on four large-scale projects, one from Microsoft and three are open source projects, i.e., Qt, Android, and OpenStack. Results: Our results show that, (i) code changes with some intents (i.e., Feature and Refactor) are more likely to be LRE changes, (ii) machine learning based prediction models are applicable for identifying LRE changes, and (iii) prediction models built for code changes with some intents achieve better performance than prediction models without considering the change intent, the improvement in AUC can be up to 19 percentage points and is 7.4 percentage points on average. Conclusion: The change intent analysis and its application on LRE identification proposed in this study has already been used in Microsoft to provide the review effort and intent information of changes for reviewers to accelerate the review process. To show how to deploy our approaches in real-world practice, we report a case study of developing and deploying the intent analysis system in Microsoft. Moreover, we also evaluate the usefulness of our approaches by using a questionnaire survey. The feedback from developers demonstrate its practical value."
"Kamimura M,Yano K,Hatano T,Matsuo A",Extracting Candidates of Microservices from Monolithic Application Code,2018,http://dx.doi.org/10.1109/APSEC.2018.00072,"Technology that facilitates rapid modification of existing business applications is necessary and it has been reported that making the system more adaptable to change is the strongest driver for legacy system modernization. There has been considerable interest in service-oriented architectures or microservices which enables the system to be quickly changed. Refactoring and, in particular, re-modularization operations can be performed to repair the design of a software system. Various approaches have been proposed to support developers during the re-modularization of a software system. The common problem in these efforts is to identify from monolithic applications the candidates of microservices, i.e., the programs or data that can be turned into cohesive, standalone services; this is a tedious manual effort that requires analyzing many dimensions of software architecture views and often heavily relies on the experience and expertise of the expert performing the extraction. To solve this problem, we developed a method that identifies the candidates of microservices from the source code by using software clustering algorithm SArF with the relation of ``program groups'' and ``data'' which we defined. Our method also visualizes the extracted candidates to show the relationship between extracted candidates and the whole structure. The candidates and visualization help the developers to capture the overview of the whole system and facilitated a dialogue with customers. We report two case studies to evaluate our results in which we applied our method to an open source application and an industrial application with our results reviewed by developers."
"Stein AJ,Kapllani L,Mancoridis S,Greenstadt R",Exploring Paraphrasing Techniques on Formal Language for Generating Semantics Preserving Source Code Transformations,2020,http://dx.doi.org/10.1109/ICSC.2020.00051,"Automatically identifying and generating equivalent semantic content to a word, phrase, or sentence is an important part of natural language processing (NLP). The research done so far in paraphrases in NLP has been focused exclusively on textual data, but has significant potential if it is applied to formal languages like source code. In this paper, we present a novel technique for generating source code transformations via the use of paraphrases. We explore how to extract and validate source code paraphrases. The transformations can be used for stylometry tasks and processes like refactoring. A machine learning method of identifying valid transformations has the advantage of avoiding the generation of transformations by hand and is more likely to have more valid transformations. Our data set is comprised by 27,300 C++ source code files, consisting of 273 topics each with 10 parallel files. This generates approximately 152,000 paraphrases. Of these paraphrases, 11% yield valid code transformations. We then train a random forest classifier that can identify valid transformations with 83% accuracy. In this paper we also discuss some of the observed relationships between linked paraphrase transformations. We depict the relationships that emerge between alternative equivalent code transformations in a graph formalism."
"Xing ZC,Stroulia E",Understanding the evolution and co-evolution of classes in object-oriented systems,2006,http://dx.doi.org/10.1142/S0218194006002707,"As software systems evolve over a long time, non-trivial and often unintended relationships among system classes arise, which cannot be easily perceived through source-code reading. As a result, the developers' understanding of continuously evolving, large, long-lived systems deteriorates steadily. A most interesting relationship is class co-evolution: because of implicit design dependencies clusters of classes change in ``parallel'' ways and recognizing such co-evolution is crucial in effectively extending and maintaining the system. In this paper, we propose a data-mining method for recovering ``hidden'' co-evolutions of system classes. This method relies on our UML-aware structural differencing algorithm, UMLDiff, which, given a sequence of UML class models of an object-oriented software system, produces a sequence of ``change records'' that describe the design-level changes over its life span. The change records are analyzed from the perspective of each individual system class to extract ``class change profiles''. Each phase of a class change profile is then discretized and classified into one of two general change types: function extension or refactoring. Finally, the Apriori association-rule mining algorithm is applied to the database of categorical class change profiles, to elicit co-evolution patterns among two or more classes, which may be as yet undocumented and unknown. The recovered knowledge facilitates the overall understanding of system evolution and the planning of future maintenance activities. We report on one real world case study evaluating our approach."
"Henderson J,Ke J,Ho JC,Ghosh J,Wallace BC",Phenotype Instance Verification and Evaluation Tool (PIVET): A Scaled Phenotype Evidence Generation Framework Using Web-Based Medical Literature,2018,http://dx.doi.org/10.2196/jmir.9610,"Background: Researchers are developing methods to automatically extract clinically relevant and useful patient characteristics from raw healthcare datasets. These characteristics, often capturing essential properties of patients with common medical conditions, are called computational phenotypes. Being generated by automated or semiautomated, data-driven methods, such potential phenotypes need to be validated as clinically meaningful (or not) before they are acceptable for use in decision making. Objective: The objective of this study was to present Phenotype Instance Verification and Evaluation Tool (PIVET), a framework that uses co-occurrence analysis on an online corpus of publically available medical journal articles to build clinical relevance evidence sets for user-supplied phenotypes. PIVET adopts a conceptual framework similar to the pioneering prototype tool PheKnow-Cloud that was developed for the phenotype validation task. PIVET completely refactors each part of the PheKnow-Cloud pipeline to deliver vast improvements in speed without sacrificing the quality of the insights PheKnow-Cloud achieved. Methods: PIVET leverages indexing in NoSQL databases to efficiently generate evidence sets. Specifically, PIVET uses a succinct representation of the phenotypes that corresponds to the index on the corpus database and an optimized co-occurrence algorithm inspired by the Aho-Corasick algorithm. We compare PIVET's phenotype representation with PheKnow-Cloud's by using PheKnow-Cloud's experimental setup. In PIVET's framework, we also introduce a statistical model trained on domain expert-verified phenotypes to automatically classify phenotypes as clinically relevant or not. Additionally, we show how the classification model can be used to examine user-supplied phenotypes in an online, rather than batch, manner. Results: PIVET maintains the discriminative power of PheKnow-Cloud in terms of identifying clinically relevant phenotypes for the same corpus with which PheKnow-Cloud was originally developed, but PIVET's analysis is an order of magnitude faster than that of PheKnow-Cloud. Not only is PIVET much faster, it can be scaled to a larger corpus and still retain speed. We evaluated multiple classification models on top of the PIVET framework and found ridge regression to perform best, realizing an average F1 score of 0.91 when predicting clinically relevant phenotypes. Conclusions: Our study shows that PIVET improves on the most notable existing computational tool for phenotype validation in terms of speed and automation and is comparable in terms of accuracy."
"Yu J,Mao C,Ye X",A Novel Tree-based Neural Network for Android Code Smells Detection,2021,http://dx.doi.org/10.1109/QRS54544.2021.00083,"The quality of mobile applications has received broad attention due to the booming development of mobile devices. Detection of Android code smells to refactor codes is an effective way to eliminate potential risks of applications. Besides traditional methods based on manually selected features, deep learning models provide an additional perspective of detection solutions. Though deep learning models are dispensed with artificial decisions, the paucity of dedicated datasets in Android code smells. The inadequate embedded syntax and semantics information acquired from source codes by token-based neural networks become new challenges. These obstacles will seriously affect the prediction performance of models. This paper put forward ACS-TNN, a novel Tree-based Neural Network approach for Android Code Smells detection. ACS-TNN took advantage of RvNN and LSTM while introducing ASTs for the first time in order to retain maximum semantic and structural information for extracting features of source codes. We constructed a dataset from practical open-source Android projects and labeled Java files data with popular Android code smells. The dataset would help researchers to train and test their deep learning models. Numerous experiments were conducted to investigate the prediction performance of ACS-TNN. The conclusions were that compared with two state-of-the-art token-based deep neural networks and another natural language tree-based model, ACS-TNN gained the best prediction performance. Further, ACS-TNN and our dataset are conducive to the maintenance of mobile applications."
"Li Y,Liu A,Zhao L,Zhang X",Hybrid Model with Multi-Level Code Representation for Multi-Label Code Smell Detection (077),2022,http://dx.doi.org/10.1142/S0218194022500723,"Code smell is an indicator of potential problems in a software design that have a negative impact on readability and maintainability. Hence, detecting code smells in a timely and effective manner can provide guides for developers in refactoring. Fortunately, many approaches like metric-based, heuristic-based, machine-learning-based and deep-learning-based have been proposed to detect code smells. However, existing methods, using the simple code representation to describe different code smells unilaterally, cannot efficiently extract enough rich information from source code. In addition, one code snippet often has several code smells at the same time and there is a lack of multi-label code smell detection based on deep learning. In this paper, we present a large-scale dataset for the multi-label code smell detection task since there is still no publicly sufficient dataset for this task. The release of this dataset would push forward the research in this field. Based on it, we propose a hybrid model with multi-level code representation to further optimize the code smell detection. First, we parse the code into the abstract syntax tree (AST) with control and data flow edges and the graph convolution network is applied to get the prediction at the syntactic and semantic level. Then we use the bidirectional long-short term memory network with attention mechanism to analyze the code tokens at the token-level in the meanwhile. Finally, we get the fusion prediction result of the models. Experimental results illustrate that our proposed model outperforms the state-of-the-art methods not only in single code smell detection but also in multi-label code smell detection."